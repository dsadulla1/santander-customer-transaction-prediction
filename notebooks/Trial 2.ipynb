{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Log:\n",
    "1. Added MinMaxScaler\n",
    "2. Same scaling for X_test and X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    Make sure to have every relevant import statement included here and return data as\n",
    "    used in model function below. This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "    import numpy\n",
    "    \n",
    "    df = pd.read_csv(\"../data/train.csv\", sep=\",\")\n",
    "    X = df[df.columns[2:]].astype(float).values\n",
    "    Y = np.array(df['target']).astype(float)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = X[:-60000,:], Y[:-60000], X[-60000:,:], Y[-60000:]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "    from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
    "    from keras.regularizers import l1_l2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}, \n",
    "                    input_shape=(X_train.shape[1],),\n",
    "                    kernel_regularizer = l1_l2(l1={{uniform(0, 1)}}, \n",
    "                                               l2={{uniform(0, 1)}})))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense({{choice([256, 512, 1024])}},\n",
    "                    kernel_regularizer = l1_l2(l1={{uniform(0, 1)}}, \n",
    "                                               l2={{uniform(0, 1)}})))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense({{choice([256, 512, 1024])}},\n",
    "                    kernel_regularizer = l1_l2(l1={{uniform(0, 1)}}, \n",
    "                                               l2={{uniform(0, 1)}})))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    checkpointer = ModelCheckpoint(filepath='../results/trial2_bestmodel.hdf5',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "    #MCP = ModelCheckpoint(filepath = \"../results/BestModel1.h5\", monitor='val_loss', verbose=0, save_best_only=True, \n",
    "    #                  save_weights_only=False, mode='auto', period=1)\n",
    "    \n",
    "    #RLROP = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, \n",
    "    #                      mode='auto', min_delta=0.00001, cooldown=1, min_lr=0)\n",
    "    \n",
    "    #CSVL = CSVLogger(filename = \"../results/LogFile1.txt\", separator=',', append=False)\n",
    "    \n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([64, 128])}},\n",
    "              epochs=20,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l1_l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential, Model, load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Input, Dense, Activation, Reshape, Dropout, PReLU, Concatenate, concatenate, multiply\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.normalization import BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.embeddings import Embedding\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import ReduceLROnPlateau, EarlyStopping, CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.constraints import nonneg\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, OneHotEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error, roc_curve, confusion_matrix, accuracy_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pickle, sys, h5py, numpy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from math import sqrt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'l1': hp.uniform('l1', 0, 1),\n",
      "        'l1_1': hp.uniform('l1_1', 0, 1),\n",
      "        'l1_2': hp.uniform('l1_2', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [256, 512, 1024]),\n",
      "        'l1_3': hp.uniform('l1_3', 0, 1),\n",
      "        'l1_4': hp.uniform('l1_4', 0, 1),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'l1_5': hp.uniform('l1_5', 0, 1),\n",
      "        'Dense_2': hp.choice('Dense_2', [256, 512, 1024]),\n",
      "        'l1_6': hp.uniform('l1_6', 0, 1),\n",
      "        'l1_7': hp.uniform('l1_7', 0, 1),\n",
      "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid']),\n",
      "        'l1_8': hp.uniform('l1_8', 0, 1),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: '''\n",
      "  3: Data providing function:\n",
      "  4: \n",
      "  5: Make sure to have every relevant import statement included here and return data as\n",
      "  6: used in model function below. This function is separated from model() so that hyperopt\n",
      "  7: won't reload data for each evaluation run.\n",
      "  8: '''\n",
      "  9: import pandas as pd\n",
      " 10: from sklearn.preprocessing import MinMaxScaler\n",
      " 11: import numpy as np\n",
      " 12: import numpy\n",
      " 13: \n",
      " 14: df = pd.read_csv(\"../data/train.csv\", sep=\",\")\n",
      " 15: X = df[df.columns[2:]].astype(float).values\n",
      " 16: Y = np.array(df['target']).astype(float)\n",
      " 17: \n",
      " 18: scaler = MinMaxScaler(feature_range=(0, 1))\n",
      " 19: X = scaler.fit_transform(X)\n",
      " 20: \n",
      " 21: X_train, Y_train, X_test, Y_test = X[:-60000,:], Y[:-60000], X[-60000:,:], Y[-60000:]\n",
      " 22: \n",
      " 23: print(X_train.shape)\n",
      " 24: print(Y_train.shape)\n",
      " 25: print(X_test.shape)\n",
      " 26: print(Y_test.shape)\n",
      " 27: \n",
      " 28: \n",
      " 29: \n",
      " 30: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     '''\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     '''\n",
      "  13: \n",
      "  14:     model = Sequential()\n",
      "  15:     model.add(Dense(space['Dense'], \n",
      "  16:                     input_shape=(X_train.shape[1],),\n",
      "  17:                     kernel_regularizer = l1_l2(l1=space['l1'], \n",
      "  18:                                                l2=space['l1_1'])))\n",
      "  19:     model.add(Activation('relu'))\n",
      "  20:     model.add(Dropout(space['l1_2']))\n",
      "  21:     \n",
      "  22:     model.add(Dense(space['Dense_1'],\n",
      "  23:                     kernel_regularizer = l1_l2(l1=space['l1_3'], \n",
      "  24:                                                l2=space['l1_4'])))\n",
      "  25:     model.add(Activation(space['Activation']))\n",
      "  26:     model.add(Dropout(space['l1_5']))\n",
      "  27:     \n",
      "  28:     model.add(Dense(space['Dense_2'],\n",
      "  29:                     kernel_regularizer = l1_l2(l1=space['l1_6'], \n",
      "  30:                                                l2=space['l1_7'])))\n",
      "  31:     model.add(Activation(space['Activation_1']))\n",
      "  32:     model.add(Dropout(space['l1_8']))\n",
      "  33:     \n",
      "  34:     model.add(Dense(1))\n",
      "  35:     model.add(Activation('sigmoid'))\n",
      "  36:     \n",
      "  37:     model.compile(loss='binary_crossentropy', optimizer=space['optimizer'])\n",
      "  38:     \n",
      "  39:     #MCP = ModelCheckpoint(filepath = \"../results/BestModel1.h5\", monitor='val_loss', verbose=0, save_best_only=True, \n",
      "  40:     #                  save_weights_only=False, mode='auto', period=1)\n",
      "  41:     \n",
      "  42:     #RLROP = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, \n",
      "  43:     #                      mode='auto', min_delta=0.00001, cooldown=1, min_lr=0)\n",
      "  44:     \n",
      "  45:     #CSVL = CSVLogger(filename = \"../results/LogFile1.txt\", separator=',', append=False)\n",
      "  46:     \n",
      "  47:     model.fit(X_train, Y_train,\n",
      "  48:               batch_size=space['batch_size'],\n",
      "  49:               epochs=20,\n",
      "  50:               verbose=2,\n",
      "  51:               validation_data=(X_test, Y_test))\n",
      "  52:     acc = model.evaluate(X_test, Y_test, verbose=0)\n",
      "  53:     print('Test accuracy:', acc)\n",
      "  54:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  55: \n",
      "(140000, 200)\n",
      "(140000,)\n",
      "(60000, 200)\n",
      "(60000,)\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 11s - loss: 890.3969 - val_loss: 860.6244\n",
      "Epoch 2/20\n",
      " - 10s - loss: 860.6258 - val_loss: 860.6177\n",
      "Epoch 3/20\n",
      " - 10s - loss: 860.6250 - val_loss: 860.6297\n",
      "Epoch 4/20\n",
      " - 10s - loss: 860.6248 - val_loss: 860.6261\n",
      "Epoch 5/20\n",
      " - 10s - loss: 860.6236 - val_loss: 860.6281\n",
      "Epoch 6/20\n",
      " - 10s - loss: 860.6230 - val_loss: 860.6297\n",
      "Epoch 7/20\n",
      " - 10s - loss: 860.6229 - val_loss: 860.6280\n",
      "Epoch 8/20\n",
      " - 10s - loss: 860.6228 - val_loss: 860.6261\n",
      "Epoch 9/20\n",
      " - 9s - loss: 860.6227 - val_loss: 860.6283\n",
      "Epoch 10/20\n",
      " - 9s - loss: 860.6224 - val_loss: 860.6258\n",
      "Epoch 11/20\n",
      " - 10s - loss: 860.6224 - val_loss: 860.6231\n",
      "Epoch 12/20\n",
      " - 10s - loss: 860.6224 - val_loss: 860.6238\n",
      "Epoch 13/20\n",
      " - 10s - loss: 860.6223 - val_loss: 860.6276\n",
      "Epoch 14/20\n",
      " - 10s - loss: 860.6220 - val_loss: 860.6264\n",
      "Epoch 15/20\n",
      " - 9s - loss: 860.6220 - val_loss: 860.6271\n",
      "Epoch 16/20\n",
      " - 10s - loss: 860.6220 - val_loss: 860.6303\n",
      "Epoch 17/20\n",
      " - 9s - loss: 860.6220 - val_loss: 860.6242\n",
      "Epoch 18/20\n",
      " - 9s - loss: 860.6221 - val_loss: 860.6237\n",
      "Epoch 19/20\n",
      " - 10s - loss: 860.6219 - val_loss: 860.6252\n",
      "Epoch 20/20\n",
      " - 10s - loss: 860.6221 - val_loss: 860.6279\n",
      "Test accuracy: 860.6279185221354\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 11s - loss: 249.1854 - val_loss: 153.1958\n",
      "Epoch 2/20\n",
      " - 10s - loss: 153.2364 - val_loss: 153.2349\n",
      "Epoch 3/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2348\n",
      "Epoch 4/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2403\n",
      "Epoch 5/20\n",
      " - 10s - loss: 153.2361 - val_loss: 153.2389\n",
      "Epoch 6/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2401\n",
      "Epoch 7/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2422\n",
      "Epoch 8/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2405\n",
      "Epoch 9/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2378\n",
      "Epoch 11/20\n",
      " - 10s - loss: 153.2361 - val_loss: 153.2375\n",
      "Epoch 12/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2383\n",
      "Epoch 13/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2392\n",
      "Epoch 14/20\n",
      " - 10s - loss: 153.2360 - val_loss: 153.2392\n",
      "Epoch 15/20\n",
      " - 10s - loss: 153.2360 - val_loss: 153.2388\n",
      "Epoch 16/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2391\n",
      "Epoch 17/20\n",
      " - 10s - loss: 153.2363 - val_loss: 153.2399\n",
      "Epoch 18/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2386\n",
      "Epoch 19/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2388\n",
      "Epoch 20/20\n",
      " - 10s - loss: 153.2362 - val_loss: 153.2394\n",
      "Test accuracy: 153.23941568196614\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 7s - loss: 467.6383 - val_loss: 60.7382\n",
      "Epoch 2/20\n",
      " - 6s - loss: 60.8071 - val_loss: 61.9462\n",
      "Epoch 3/20\n",
      " - 6s - loss: 61.7078 - val_loss: 62.0194\n",
      "Epoch 4/20\n",
      " - 6s - loss: 61.7153 - val_loss: 61.5264\n",
      "Epoch 5/20\n",
      " - 6s - loss: 61.6998 - val_loss: 61.5269\n",
      "Epoch 6/20\n",
      " - 6s - loss: 61.6934 - val_loss: 61.4790\n",
      "Epoch 7/20\n",
      " - 6s - loss: 61.6772 - val_loss: 61.9969\n",
      "Epoch 8/20\n",
      " - 6s - loss: 61.6658 - val_loss: 61.6381\n",
      "Epoch 9/20\n",
      " - 6s - loss: 61.6700 - val_loss: 61.9006\n",
      "Epoch 10/20\n",
      " - 6s - loss: 61.6841 - val_loss: 61.0009\n",
      "Epoch 11/20\n",
      " - 6s - loss: 61.6822 - val_loss: 61.9384\n",
      "Epoch 12/20\n",
      " - 6s - loss: 61.6963 - val_loss: 61.9733\n",
      "Epoch 13/20\n",
      " - 6s - loss: 61.7042 - val_loss: 61.7925\n",
      "Epoch 14/20\n",
      " - 6s - loss: 61.7270 - val_loss: 61.3262\n",
      "Epoch 15/20\n",
      " - 6s - loss: 61.7461 - val_loss: 62.0388\n",
      "Epoch 16/20\n",
      " - 6s - loss: 61.7624 - val_loss: 61.6836\n",
      "Epoch 17/20\n",
      " - 6s - loss: 61.7782 - val_loss: 61.9218\n",
      "Epoch 18/20\n",
      " - 6s - loss: 61.7956 - val_loss: 61.9450\n",
      "Epoch 19/20\n",
      " - 6s - loss: 61.8164 - val_loss: 61.9464\n",
      "Epoch 20/20\n",
      " - 6s - loss: 61.8378 - val_loss: 61.5362\n",
      "Test accuracy: 61.53617221883138\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 151.4871 - val_loss: 29.1641\n",
      "Epoch 2/20\n",
      " - 11s - loss: 29.4326 - val_loss: 29.9033\n",
      "Epoch 3/20\n",
      " - 11s - loss: 30.1016 - val_loss: 30.1467\n",
      "Epoch 4/20\n",
      " - 11s - loss: 30.2107 - val_loss: 30.2060\n",
      "Epoch 5/20\n",
      " - 11s - loss: 30.2156 - val_loss: 29.9527\n",
      "Epoch 6/20\n",
      " - 11s - loss: 30.2211 - val_loss: 30.3744\n",
      "Epoch 7/20\n",
      " - 11s - loss: 30.2352 - val_loss: 29.9992\n",
      "Epoch 8/20\n",
      " - 11s - loss: 30.2482 - val_loss: 30.2730\n",
      "Epoch 9/20\n",
      " - 11s - loss: 30.2582 - val_loss: 30.2329\n",
      "Epoch 10/20\n",
      " - 11s - loss: 30.2685 - val_loss: 30.1514\n",
      "Epoch 11/20\n",
      " - 11s - loss: 30.2746 - val_loss: 30.3846\n",
      "Epoch 12/20\n",
      " - 11s - loss: 30.2741 - val_loss: 30.0864\n",
      "Epoch 13/20\n",
      " - 11s - loss: 30.2697 - val_loss: 30.2568\n",
      "Epoch 14/20\n",
      " - 11s - loss: 30.2658 - val_loss: 30.1086\n",
      "Epoch 15/20\n",
      " - 11s - loss: 30.2611 - val_loss: 30.2501\n",
      "Epoch 16/20\n",
      " - 11s - loss: 30.2592 - val_loss: 30.2483\n",
      "Epoch 17/20\n",
      " - 11s - loss: 30.2552 - val_loss: 30.1207\n",
      "Epoch 18/20\n",
      " - 11s - loss: 30.2518 - val_loss: 30.2870\n",
      "Epoch 19/20\n",
      " - 11s - loss: 30.2475 - val_loss: 30.1034\n",
      "Epoch 20/20\n",
      " - 11s - loss: 30.2468 - val_loss: 30.1291\n",
      "Test accuracy: 30.129061173502603\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 8s - loss: 786.8507 - val_loss: 416.2688\n",
      "Epoch 2/20\n",
      " - 7s - loss: 416.6213 - val_loss: 416.5615\n",
      "Epoch 3/20\n",
      " - 7s - loss: 416.6203 - val_loss: 416.6059\n",
      "Epoch 4/20\n",
      " - 7s - loss: 416.6199 - val_loss: 416.6233\n",
      "Epoch 5/20\n",
      " - 7s - loss: 416.6194 - val_loss: 416.6179\n",
      "Epoch 6/20\n",
      " - 7s - loss: 416.6195 - val_loss: 416.6221\n",
      "Epoch 7/20\n",
      " - 7s - loss: 416.6196 - val_loss: 416.6224\n",
      "Epoch 8/20\n",
      " - 7s - loss: 416.6197 - val_loss: 416.6210\n",
      "Epoch 9/20\n",
      " - 7s - loss: 416.6193 - val_loss: 416.6173\n",
      "Epoch 10/20\n",
      " - 7s - loss: 416.6190 - val_loss: 416.6181\n",
      "Epoch 11/20\n",
      " - 7s - loss: 416.6189 - val_loss: 416.6202\n",
      "Epoch 12/20\n",
      " - 7s - loss: 416.6189 - val_loss: 416.6208\n",
      "Epoch 13/20\n",
      " - 7s - loss: 416.6187 - val_loss: 416.6201\n",
      "Epoch 14/20\n",
      " - 7s - loss: 416.6182 - val_loss: 416.6187\n",
      "Epoch 15/20\n",
      " - 7s - loss: 416.6181 - val_loss: 416.6179\n",
      "Epoch 16/20\n",
      " - 7s - loss: 416.6184 - val_loss: 416.6191\n",
      "Epoch 17/20\n",
      " - 7s - loss: 416.6180 - val_loss: 416.6187\n",
      "Epoch 18/20\n",
      " - 7s - loss: 416.6181 - val_loss: 416.6208\n",
      "Epoch 19/20\n",
      " - 7s - loss: 416.6179 - val_loss: 416.6197\n",
      "Epoch 20/20\n",
      " - 7s - loss: 416.6177 - val_loss: 416.6201\n",
      "Test accuracy: 416.62012760416667\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 10s - loss: 274.7151 - val_loss: 250.4143\n",
      "Epoch 2/20\n",
      " - 9s - loss: 250.4187 - val_loss: 250.4052\n",
      "Epoch 3/20\n",
      " - 9s - loss: 250.4174 - val_loss: 250.4328\n",
      "Epoch 4/20\n",
      " - 9s - loss: 250.4170 - val_loss: 250.4233\n",
      "Epoch 5/20\n",
      " - 9s - loss: 250.4166 - val_loss: 250.4106\n",
      "Epoch 6/20\n",
      " - 9s - loss: 250.4163 - val_loss: 250.4214\n",
      "Epoch 7/20\n",
      " - 9s - loss: 250.4158 - val_loss: 250.4137\n",
      "Epoch 8/20\n",
      " - 9s - loss: 250.4155 - val_loss: 250.4217\n",
      "Epoch 9/20\n",
      " - 9s - loss: 250.4153 - val_loss: 250.4185\n",
      "Epoch 10/20\n",
      " - 9s - loss: 250.4152 - val_loss: 250.4148\n",
      "Epoch 11/20\n",
      " - 9s - loss: 250.4149 - val_loss: 250.4111\n",
      "Epoch 12/20\n",
      " - 9s - loss: 250.4151 - val_loss: 250.4053\n",
      "Epoch 13/20\n",
      " - 9s - loss: 250.4148 - val_loss: 250.4127\n",
      "Epoch 14/20\n",
      " - 9s - loss: 250.4146 - val_loss: 250.4256\n",
      "Epoch 15/20\n",
      " - 9s - loss: 250.4147 - val_loss: 250.4135\n",
      "Epoch 16/20\n",
      " - 9s - loss: 250.4146 - val_loss: 250.4193\n",
      "Epoch 17/20\n",
      " - 9s - loss: 250.4145 - val_loss: 250.4229\n",
      "Epoch 18/20\n",
      " - 9s - loss: 250.4146 - val_loss: 250.4125\n",
      "Epoch 19/20\n",
      " - 9s - loss: 250.4144 - val_loss: 250.4243\n",
      "Epoch 20/20\n",
      " - 9s - loss: 250.4144 - val_loss: 250.4158\n",
      "Test accuracy: 250.4157596842448\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 7s - loss: 349.6305 - val_loss: 161.8515\n",
      "Epoch 2/20\n",
      " - 5s - loss: 162.2509 - val_loss: 161.9228\n",
      "Epoch 3/20\n",
      " - 5s - loss: 162.2508 - val_loss: 161.9487\n",
      "Epoch 4/20\n",
      " - 5s - loss: 162.2508 - val_loss: 161.9672\n",
      "Epoch 5/20\n",
      " - 5s - loss: 162.2508 - val_loss: 161.9817\n",
      "Epoch 6/20\n",
      " - 5s - loss: 162.2508 - val_loss: 161.9866\n",
      "Epoch 7/20\n",
      " - 5s - loss: 162.2509 - val_loss: 162.0040\n",
      "Epoch 8/20\n",
      " - 5s - loss: 162.2510 - val_loss: 162.0140\n",
      "Epoch 9/20\n",
      " - 5s - loss: 162.2505 - val_loss: 162.0353\n",
      "Epoch 10/20\n",
      " - 6s - loss: 162.2508 - val_loss: 162.0430\n",
      "Epoch 11/20\n",
      " - 5s - loss: 162.2508 - val_loss: 162.0536\n",
      "Epoch 12/20\n",
      " - 5s - loss: 162.2507 - val_loss: 162.0684\n",
      "Epoch 13/20\n",
      " - 5s - loss: 162.2506 - val_loss: 162.0779\n",
      "Epoch 14/20\n",
      " - 5s - loss: 162.2506 - val_loss: 162.0810\n",
      "Epoch 15/20\n",
      " - 5s - loss: 162.2509 - val_loss: 162.0894\n",
      "Epoch 16/20\n",
      " - 6s - loss: 162.2510 - val_loss: 162.1007\n",
      "Epoch 17/20\n",
      " - 5s - loss: 162.2509 - val_loss: 162.1091\n",
      "Epoch 18/20\n",
      " - 5s - loss: 162.2507 - val_loss: 162.1133\n",
      "Epoch 19/20\n",
      " - 5s - loss: 162.2510 - val_loss: 162.1250\n",
      "Epoch 20/20\n",
      " - 6s - loss: 162.2511 - val_loss: 162.1288\n",
      "Test accuracy: 162.12880599772134\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 13s - loss: 1707.7542 - val_loss: 1670.6357\n",
      "Epoch 2/20\n",
      " - 11s - loss: 1670.5697 - val_loss: 1670.5736\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1670.5696 - val_loss: 1670.5717\n",
      "Epoch 4/20\n",
      " - 11s - loss: 1670.5696 - val_loss: 1670.5728\n",
      "Epoch 5/20\n",
      " - 11s - loss: 1670.5695 - val_loss: 1670.5728\n",
      "Epoch 6/20\n",
      " - 11s - loss: 1670.5696 - val_loss: 1670.5722\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1670.5694 - val_loss: 1670.5722\n",
      "Epoch 8/20\n",
      " - 11s - loss: 1670.5692 - val_loss: 1670.5717\n",
      "Epoch 9/20\n",
      " - 11s - loss: 1670.5693 - val_loss: 1670.5725\n",
      "Epoch 10/20\n",
      " - 11s - loss: 1670.5692 - val_loss: 1670.5727\n",
      "Epoch 11/20\n",
      " - 11s - loss: 1670.5692 - val_loss: 1670.5723\n",
      "Epoch 12/20\n",
      " - 11s - loss: 1670.5690 - val_loss: 1670.5725\n",
      "Epoch 13/20\n",
      " - 11s - loss: 1670.5692 - val_loss: 1670.5726\n",
      "Epoch 14/20\n",
      " - 11s - loss: 1670.5692 - val_loss: 1670.5719\n",
      "Epoch 15/20\n",
      " - 11s - loss: 1670.5691 - val_loss: 1670.5723\n",
      "Epoch 16/20\n",
      " - 11s - loss: 1670.5690 - val_loss: 1670.5721\n",
      "Epoch 17/20\n",
      " - 11s - loss: 1670.5691 - val_loss: 1670.5726\n",
      "Epoch 18/20\n",
      " - 11s - loss: 1670.5689 - val_loss: 1670.5721\n",
      "Epoch 19/20\n",
      " - 11s - loss: 1670.5691 - val_loss: 1670.5718\n",
      "Epoch 20/20\n",
      " - 11s - loss: 1670.5691 - val_loss: 1670.5724\n",
      "Test accuracy: 1670.5723717447916\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 278.4541 - val_loss: 143.2766\n",
      "Epoch 2/20\n",
      " - 10s - loss: 143.2932 - val_loss: 143.2951\n",
      "Epoch 3/20\n",
      " - 10s - loss: 143.2923 - val_loss: 143.2925\n",
      "Epoch 4/20\n",
      " - 10s - loss: 143.2918 - val_loss: 143.2932\n",
      "Epoch 5/20\n",
      " - 10s - loss: 143.2915 - val_loss: 143.2966\n",
      "Epoch 6/20\n",
      " - 10s - loss: 143.2912 - val_loss: 143.2954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      " - 10s - loss: 143.2911 - val_loss: 143.3065\n",
      "Epoch 8/20\n",
      " - 10s - loss: 143.2909 - val_loss: 143.2934\n",
      "Epoch 9/20\n",
      " - 10s - loss: 143.2908 - val_loss: 143.2938\n",
      "Epoch 10/20\n",
      " - 10s - loss: 143.2907 - val_loss: 143.2934\n",
      "Epoch 11/20\n",
      " - 10s - loss: 143.2906 - val_loss: 143.2994\n",
      "Epoch 12/20\n",
      " - 10s - loss: 143.2905 - val_loss: 143.2991\n",
      "Epoch 13/20\n",
      " - 10s - loss: 143.2906 - val_loss: 143.2929\n",
      "Epoch 14/20\n",
      " - 10s - loss: 143.2906 - val_loss: 143.2928\n",
      "Epoch 15/20\n",
      " - 10s - loss: 143.2903 - val_loss: 143.2934\n",
      "Epoch 16/20\n",
      " - 10s - loss: 143.2902 - val_loss: 143.2989\n",
      "Epoch 17/20\n",
      " - 10s - loss: 143.2903 - val_loss: 143.2940\n",
      "Epoch 18/20\n",
      " - 10s - loss: 143.2901 - val_loss: 143.2926\n",
      "Epoch 19/20\n",
      " - 10s - loss: 143.2901 - val_loss: 143.2926\n",
      "Epoch 20/20\n",
      " - 10s - loss: 143.2902 - val_loss: 143.2960\n",
      "Test accuracy: 143.29599704589845\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 13s - loss: 63.6632 - val_loss: 13.7788\n",
      "Epoch 2/20\n",
      " - 11s - loss: 13.8191 - val_loss: 13.8246\n",
      "Epoch 3/20\n",
      " - 11s - loss: 13.8234 - val_loss: 13.8500\n",
      "Epoch 4/20\n",
      " - 11s - loss: 13.8239 - val_loss: 13.8137\n",
      "Epoch 5/20\n",
      " - 11s - loss: 13.8234 - val_loss: 13.7264\n",
      "Epoch 6/20\n",
      " - 11s - loss: 13.8242 - val_loss: 13.8688\n",
      "Epoch 7/20\n",
      " - 11s - loss: 13.8244 - val_loss: 13.8247\n",
      "Epoch 8/20\n",
      " - 11s - loss: 13.8254 - val_loss: 13.7087\n",
      "Epoch 9/20\n",
      " - 11s - loss: 13.8255 - val_loss: 13.9764\n",
      "Epoch 10/20\n",
      " - 11s - loss: 13.8260 - val_loss: 13.7485\n",
      "Epoch 11/20\n",
      " - 11s - loss: 13.8268 - val_loss: 13.7790\n",
      "Epoch 12/20\n",
      " - 11s - loss: 13.8265 - val_loss: 13.9502\n",
      "Epoch 13/20\n",
      " - 11s - loss: 13.8274 - val_loss: 13.6763\n",
      "Epoch 14/20\n",
      " - 11s - loss: 13.8270 - val_loss: 13.7966\n",
      "Epoch 15/20\n",
      " - 11s - loss: 13.8268 - val_loss: 13.8862\n",
      "Epoch 16/20\n",
      " - 11s - loss: 13.8266 - val_loss: 13.8297\n",
      "Epoch 17/20\n",
      " - 11s - loss: 13.8270 - val_loss: 13.7757\n",
      "Epoch 18/20\n",
      " - 11s - loss: 13.8267 - val_loss: 13.8934\n",
      "Epoch 19/20\n",
      " - 11s - loss: 13.8268 - val_loss: 13.7734\n",
      "Epoch 20/20\n",
      " - 11s - loss: 13.8267 - val_loss: 13.7126\n",
      "Test accuracy: 13.712580922444662\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 21s - loss: 404.2837 - val_loss: 122.5284\n",
      "Epoch 2/20\n",
      " - 18s - loss: 122.5707 - val_loss: 122.6182\n",
      "Epoch 3/20\n",
      " - 18s - loss: 124.3990 - val_loss: 125.7250\n",
      "Epoch 4/20\n",
      " - 18s - loss: 125.9228 - val_loss: 126.1268\n",
      "Epoch 5/20\n",
      " - 18s - loss: 126.0370 - val_loss: 124.7069\n",
      "Epoch 6/20\n",
      " - 18s - loss: 126.0722 - val_loss: 126.4868\n",
      "Epoch 7/20\n",
      " - 18s - loss: 126.0772 - val_loss: 125.0175\n",
      "Epoch 8/20\n",
      " - 18s - loss: 126.0907 - val_loss: 125.6993\n",
      "Epoch 9/20\n",
      " - 18s - loss: 126.0987 - val_loss: 126.2895\n",
      "Epoch 10/20\n",
      " - 18s - loss: 126.0995 - val_loss: 125.6099\n",
      "Epoch 11/20\n",
      " - 18s - loss: 126.1014 - val_loss: 126.2244\n",
      "Epoch 12/20\n",
      " - 18s - loss: 126.1078 - val_loss: 125.6617\n",
      "Epoch 13/20\n",
      " - 18s - loss: 126.1023 - val_loss: 125.9116\n",
      "Epoch 14/20\n",
      " - 18s - loss: 126.0953 - val_loss: 125.4654\n",
      "Epoch 15/20\n",
      " - 18s - loss: 126.0987 - val_loss: 126.0505\n",
      "Epoch 16/20\n",
      " - 18s - loss: 126.0910 - val_loss: 126.2034\n",
      "Epoch 17/20\n",
      " - 18s - loss: 126.0907 - val_loss: 125.2303\n",
      "Epoch 18/20\n",
      " - 18s - loss: 126.0880 - val_loss: 126.2150\n",
      "Epoch 19/20\n",
      " - 18s - loss: 126.0839 - val_loss: 125.5793\n",
      "Epoch 20/20\n",
      " - 18s - loss: 126.0862 - val_loss: 125.0247\n",
      "Test accuracy: 125.02465631917318\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 198.6160 - val_loss: 50.8240\n",
      "Epoch 2/20\n",
      " - 14s - loss: 51.2636 - val_loss: 51.5508\n",
      "Epoch 3/20\n",
      " - 13s - loss: 52.3779 - val_loss: 52.4555\n",
      "Epoch 4/20\n",
      " - 13s - loss: 52.6772 - val_loss: 52.7070\n",
      "Epoch 5/20\n",
      " - 13s - loss: 52.7121 - val_loss: 52.1005\n",
      "Epoch 6/20\n",
      " - 14s - loss: 52.7213 - val_loss: 52.9793\n",
      "Epoch 7/20\n",
      " - 14s - loss: 52.7144 - val_loss: 52.1587\n",
      "Epoch 8/20\n",
      " - 13s - loss: 52.7093 - val_loss: 52.8095\n",
      "Epoch 9/20\n",
      " - 13s - loss: 52.7129 - val_loss: 52.5864\n",
      "Epoch 10/20\n",
      " - 14s - loss: 52.7158 - val_loss: 52.4175\n",
      "Epoch 11/20\n",
      " - 14s - loss: 52.7155 - val_loss: 52.9234\n",
      "Epoch 12/20\n",
      " - 13s - loss: 52.7188 - val_loss: 52.2965\n",
      "Epoch 13/20\n",
      " - 14s - loss: 52.7179 - val_loss: 52.7274\n",
      "Epoch 14/20\n",
      " - 14s - loss: 52.7162 - val_loss: 52.3332\n",
      "Epoch 15/20\n",
      " - 14s - loss: 52.7179 - val_loss: 52.7048\n",
      "Epoch 16/20\n",
      " - 13s - loss: 52.7173 - val_loss: 52.6762\n",
      "Epoch 17/20\n",
      " - 13s - loss: 52.7173 - val_loss: 52.4959\n",
      "Epoch 18/20\n",
      " - 13s - loss: 52.7168 - val_loss: 52.7398\n",
      "Epoch 19/20\n",
      " - 13s - loss: 52.7223 - val_loss: 52.3581\n",
      "Epoch 20/20\n",
      " - 13s - loss: 52.7215 - val_loss: 52.4527\n",
      "Test accuracy: 52.45270342610677\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 633.8788 - val_loss: 67.9606\n",
      "Epoch 2/20\n",
      " - 6s - loss: 66.8385 - val_loss: 66.8774\n",
      "Epoch 3/20\n",
      " - 6s - loss: 66.7305 - val_loss: 67.3118\n",
      "Epoch 4/20\n",
      " - 6s - loss: 67.6625 - val_loss: 67.7652\n",
      "Epoch 5/20\n",
      " - 6s - loss: 68.2462 - val_loss: 68.5572\n",
      "Epoch 6/20\n",
      " - 6s - loss: 68.9289 - val_loss: 69.0116\n",
      "Epoch 7/20\n",
      " - 6s - loss: 69.1485 - val_loss: 69.2910\n",
      "Epoch 8/20\n",
      " - 6s - loss: 69.1600 - val_loss: 69.2531\n",
      "Epoch 9/20\n",
      " - 6s - loss: 69.1807 - val_loss: 69.5081\n",
      "Epoch 10/20\n",
      " - 6s - loss: 69.1902 - val_loss: 68.3181\n",
      "Epoch 11/20\n",
      " - 6s - loss: 69.1868 - val_loss: 69.4731\n",
      "Epoch 12/20\n",
      " - 6s - loss: 69.1853 - val_loss: 69.4928\n",
      "Epoch 13/20\n",
      " - 6s - loss: 69.1833 - val_loss: 69.1955\n",
      "Epoch 14/20\n",
      " - 6s - loss: 69.1832 - val_loss: 68.7005\n",
      "Epoch 15/20\n",
      " - 6s - loss: 69.1838 - val_loss: 69.5563\n",
      "Epoch 16/20\n",
      " - 6s - loss: 69.1848 - val_loss: 69.1263\n",
      "Epoch 17/20\n",
      " - 6s - loss: 69.1843 - val_loss: 69.3535\n",
      "Epoch 18/20\n",
      " - 6s - loss: 69.1851 - val_loss: 69.3377\n",
      "Epoch 19/20\n",
      " - 6s - loss: 69.1858 - val_loss: 69.1554\n",
      "Epoch 20/20\n",
      " - 6s - loss: 69.1861 - val_loss: 68.9052\n",
      "Test accuracy: 68.90521265462239\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 8s - loss: 377.6931 - val_loss: 155.2536\n",
      "Epoch 2/20\n",
      " - 6s - loss: 155.3071 - val_loss: 155.2742\n",
      "Epoch 3/20\n",
      " - 6s - loss: 155.3065 - val_loss: 155.2811\n",
      "Epoch 4/20\n",
      " - 6s - loss: 155.3061 - val_loss: 155.2893\n",
      "Epoch 5/20\n",
      " - 6s - loss: 155.3059 - val_loss: 155.2926\n",
      "Epoch 6/20\n",
      " - 6s - loss: 155.3056 - val_loss: 155.2983\n",
      "Epoch 7/20\n",
      " - 6s - loss: 155.3057 - val_loss: 155.2987\n",
      "Epoch 8/20\n",
      " - 6s - loss: 155.3054 - val_loss: 155.3006\n",
      "Epoch 9/20\n",
      " - 6s - loss: 155.3053 - val_loss: 155.3023\n",
      "Epoch 10/20\n",
      " - 6s - loss: 155.3052 - val_loss: 155.3062\n",
      "Epoch 11/20\n",
      " - 6s - loss: 155.3051 - val_loss: 155.3043\n",
      "Epoch 12/20\n",
      " - 6s - loss: 155.3050 - val_loss: 155.3088\n",
      "Epoch 13/20\n",
      " - 6s - loss: 155.3051 - val_loss: 155.3090\n",
      "Epoch 14/20\n",
      " - 6s - loss: 155.3051 - val_loss: 155.3066\n",
      "Epoch 15/20\n",
      " - 6s - loss: 155.3049 - val_loss: 155.3064\n",
      "Epoch 16/20\n",
      " - 6s - loss: 155.3049 - val_loss: 155.3062\n",
      "Epoch 17/20\n",
      " - 6s - loss: 155.3049 - val_loss: 155.3065\n",
      "Epoch 18/20\n",
      " - 6s - loss: 155.3049 - val_loss: 155.3201\n",
      "Epoch 19/20\n",
      " - 6s - loss: 155.3048 - val_loss: 155.3066\n",
      "Epoch 20/20\n",
      " - 6s - loss: 155.3049 - val_loss: 155.3078\n",
      "Test accuracy: 155.3077629638672\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 11s - loss: 652.1898 - val_loss: 113.8112\n",
      "Epoch 2/20\n",
      " - 8s - loss: 111.7922 - val_loss: 111.0798\n",
      "Epoch 3/20\n",
      " - 8s - loss: 111.3720 - val_loss: 112.2341\n",
      "Epoch 4/20\n",
      " - 8s - loss: 111.6594 - val_loss: 111.6611\n",
      "Epoch 5/20\n",
      " - 8s - loss: 113.3424 - val_loss: 114.3820\n",
      "Epoch 6/20\n",
      " - 8s - loss: 114.5278 - val_loss: 114.3621\n",
      "Epoch 7/20\n",
      " - 8s - loss: 114.5947 - val_loss: 114.9929\n",
      "Epoch 8/20\n",
      " - 8s - loss: 114.7386 - val_loss: 114.8157\n",
      "Epoch 9/20\n",
      " - 8s - loss: 114.9691 - val_loss: 116.0446\n",
      "Epoch 10/20\n",
      " - 8s - loss: 115.2559 - val_loss: 114.0060\n",
      "Epoch 11/20\n",
      " - 8s - loss: 115.3485 - val_loss: 115.9543\n",
      "Epoch 12/20\n",
      " - 8s - loss: 115.3597 - val_loss: 115.6964\n",
      "Epoch 13/20\n",
      " - 8s - loss: 115.3653 - val_loss: 115.1951\n",
      "Epoch 14/20\n",
      " - 8s - loss: 115.3720 - val_loss: 114.2556\n",
      "Epoch 15/20\n",
      " - 8s - loss: 115.3792 - val_loss: 116.4320\n",
      "Epoch 16/20\n",
      " - 8s - loss: 115.3866 - val_loss: 115.1139\n",
      "Epoch 17/20\n",
      " - 8s - loss: 115.3864 - val_loss: 115.1450\n",
      "Epoch 18/20\n",
      " - 8s - loss: 115.3883 - val_loss: 115.3977\n",
      "Epoch 19/20\n",
      " - 8s - loss: 115.3892 - val_loss: 115.6467\n",
      "Epoch 20/20\n",
      " - 8s - loss: 115.3888 - val_loss: 114.9100\n",
      "Test accuracy: 114.91002352294922\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 339.4627 - val_loss: 44.8779\n",
      "Epoch 2/20\n",
      " - 6s - loss: 44.4069 - val_loss: 44.2755\n",
      "Epoch 3/20\n",
      " - 6s - loss: 44.0259 - val_loss: 44.0156\n",
      "Epoch 4/20\n",
      " - 6s - loss: 43.9650 - val_loss: 44.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      " - 6s - loss: 44.2309 - val_loss: 44.0917\n",
      "Epoch 6/20\n",
      " - 6s - loss: 44.3128 - val_loss: 44.2265\n",
      "Epoch 7/20\n",
      " - 6s - loss: 44.6199 - val_loss: 45.0620\n",
      "Epoch 8/20\n",
      " - 6s - loss: 45.2373 - val_loss: 45.3989\n",
      "Epoch 9/20\n",
      " - 6s - loss: 45.4641 - val_loss: 45.6503\n",
      "Epoch 10/20\n",
      " - 6s - loss: 45.4803 - val_loss: 45.1657\n",
      "Epoch 11/20\n",
      " - 6s - loss: 45.4860 - val_loss: 45.6713\n",
      "Epoch 12/20\n",
      " - 6s - loss: 45.5042 - val_loss: 45.6299\n",
      "Epoch 13/20\n",
      " - 6s - loss: 45.5121 - val_loss: 45.4702\n",
      "Epoch 14/20\n",
      " - 6s - loss: 45.5115 - val_loss: 45.1334\n",
      "Epoch 15/20\n",
      " - 6s - loss: 45.5103 - val_loss: 45.8134\n",
      "Epoch 16/20\n",
      " - 6s - loss: 45.5078 - val_loss: 45.5841\n",
      "Epoch 17/20\n",
      " - 6s - loss: 45.5055 - val_loss: 45.4302\n",
      "Epoch 18/20\n",
      " - 6s - loss: 45.5031 - val_loss: 45.4547\n",
      "Epoch 19/20\n",
      " - 6s - loss: 45.5000 - val_loss: 45.5897\n",
      "Epoch 20/20\n",
      " - 6s - loss: 45.4959 - val_loss: 45.3578\n",
      "Test accuracy: 45.357769767252606\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 10s - loss: 339.3680 - val_loss: 40.9927\n",
      "Epoch 2/20\n",
      " - 6s - loss: 40.8478 - val_loss: 41.1550\n",
      "Epoch 3/20\n",
      " - 6s - loss: 41.3229 - val_loss: 41.8479\n",
      "Epoch 4/20\n",
      " - 6s - loss: 41.8283 - val_loss: 41.8597\n",
      "Epoch 5/20\n",
      " - 7s - loss: 41.9086 - val_loss: 41.8964\n",
      "Epoch 6/20\n",
      " - 6s - loss: 41.9509 - val_loss: 41.8221\n",
      "Epoch 7/20\n",
      " - 6s - loss: 41.9690 - val_loss: 42.0975\n",
      "Epoch 8/20\n",
      " - 6s - loss: 41.9765 - val_loss: 42.1581\n",
      "Epoch 9/20\n",
      " - 6s - loss: 41.9791 - val_loss: 42.1714\n",
      "Epoch 10/20\n",
      " - 6s - loss: 41.9794 - val_loss: 41.5761\n",
      "Epoch 11/20\n",
      " - 6s - loss: 41.9772 - val_loss: 42.0780\n",
      "Epoch 12/20\n",
      " - 6s - loss: 41.9729 - val_loss: 42.1090\n",
      "Epoch 13/20\n",
      " - 6s - loss: 41.9681 - val_loss: 41.9993\n",
      "Epoch 14/20\n",
      " - 6s - loss: 41.9669 - val_loss: 41.8262\n",
      "Epoch 15/20\n",
      " - 7s - loss: 41.9658 - val_loss: 42.1079\n",
      "Epoch 16/20\n",
      " - 7s - loss: 41.9643 - val_loss: 41.8909\n",
      "Epoch 17/20\n",
      " - 6s - loss: 41.9640 - val_loss: 41.9795\n",
      "Epoch 18/20\n",
      " - 6s - loss: 41.9639 - val_loss: 42.0836\n",
      "Epoch 19/20\n",
      " - 6s - loss: 41.9643 - val_loss: 42.0790\n",
      "Epoch 20/20\n",
      " - 6s - loss: 41.9640 - val_loss: 41.8845\n",
      "Test accuracy: 41.88453946736654\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 14s - loss: 228.4015 - val_loss: 133.7422\n",
      "Epoch 2/20\n",
      " - 11s - loss: 133.7828 - val_loss: 133.7769\n",
      "Epoch 3/20\n",
      " - 11s - loss: 133.7826 - val_loss: 133.7773\n",
      "Epoch 4/20\n",
      " - 11s - loss: 133.7824 - val_loss: 133.7816\n",
      "Epoch 5/20\n",
      " - 11s - loss: 133.7826 - val_loss: 133.7796\n",
      "Epoch 6/20\n",
      " - 11s - loss: 133.7819 - val_loss: 133.7867\n",
      "Epoch 7/20\n",
      " - 11s - loss: 133.7817 - val_loss: 133.7846\n",
      "Epoch 8/20\n",
      " - 11s - loss: 133.7817 - val_loss: 133.7834\n",
      "Epoch 9/20\n",
      " - 11s - loss: 133.7812 - val_loss: 133.7819\n",
      "Epoch 10/20\n",
      " - 11s - loss: 133.7817 - val_loss: 133.7866\n",
      "Epoch 11/20\n",
      " - 11s - loss: 133.7809 - val_loss: 133.7884\n",
      "Epoch 12/20\n",
      " - 11s - loss: 133.7811 - val_loss: 133.7828\n",
      "Epoch 13/20\n",
      " - 11s - loss: 133.7808 - val_loss: 133.7840\n",
      "Epoch 14/20\n",
      " - 11s - loss: 133.7809 - val_loss: 133.7859\n",
      "Epoch 15/20\n",
      " - 11s - loss: 133.7808 - val_loss: 133.7849\n",
      "Epoch 16/20\n",
      " - 11s - loss: 133.7808 - val_loss: 133.7858\n",
      "Epoch 17/20\n",
      " - 11s - loss: 133.7802 - val_loss: 133.7847\n",
      "Epoch 18/20\n",
      " - 11s - loss: 133.7803 - val_loss: 133.7822\n",
      "Epoch 19/20\n",
      " - 11s - loss: 133.7804 - val_loss: 133.7795\n",
      "Epoch 20/20\n",
      " - 11s - loss: 133.7803 - val_loss: 133.7853\n",
      "Test accuracy: 133.78526263020834\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 14s - loss: 349.8580 - val_loss: 215.0884\n",
      "Epoch 2/20\n",
      " - 11s - loss: 215.2042 - val_loss: 215.1150\n",
      "Epoch 3/20\n",
      " - 11s - loss: 215.2054 - val_loss: 215.1338\n",
      "Epoch 4/20\n",
      " - 11s - loss: 215.2055 - val_loss: 215.1464\n",
      "Epoch 5/20\n",
      " - 11s - loss: 215.2055 - val_loss: 215.1560\n",
      "Epoch 6/20\n",
      " - 11s - loss: 215.2062 - val_loss: 215.1665\n",
      "Epoch 7/20\n",
      " - 11s - loss: 215.2070 - val_loss: 215.1744\n",
      "Epoch 8/20\n",
      " - 11s - loss: 215.2067 - val_loss: 215.1815\n",
      "Epoch 9/20\n",
      " - 11s - loss: 215.2070 - val_loss: 215.1856\n",
      "Epoch 10/20\n",
      " - 11s - loss: 215.2072 - val_loss: 215.1902\n",
      "Epoch 11/20\n",
      " - 11s - loss: 215.2070 - val_loss: 215.1940\n",
      "Epoch 12/20\n",
      " - 11s - loss: 215.2071 - val_loss: 215.1959\n",
      "Epoch 13/20\n",
      " - 11s - loss: 215.2075 - val_loss: 215.2006\n",
      "Epoch 14/20\n",
      " - 11s - loss: 215.2077 - val_loss: 215.2010\n",
      "Epoch 15/20\n",
      " - 11s - loss: 215.2079 - val_loss: 215.2037\n",
      "Epoch 16/20\n",
      " - 11s - loss: 215.2081 - val_loss: 215.2048\n",
      "Epoch 17/20\n",
      " - 11s - loss: 215.2083 - val_loss: 215.2062\n",
      "Epoch 18/20\n",
      " - 11s - loss: 215.2084 - val_loss: 215.2074\n",
      "Epoch 19/20\n",
      " - 11s - loss: 215.2085 - val_loss: 215.2078\n",
      "Epoch 20/20\n",
      " - 11s - loss: 215.2083 - val_loss: 215.2091\n",
      "Test accuracy: 215.20913411458332\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 22s - loss: 460.6605 - val_loss: 144.2033\n",
      "Epoch 2/20\n",
      " - 18s - loss: 144.6388 - val_loss: 144.2778\n",
      "Epoch 3/20\n",
      " - 18s - loss: 145.0567 - val_loss: 145.3102\n",
      "Epoch 4/20\n",
      " - 18s - loss: 145.4327 - val_loss: 145.6209\n",
      "Epoch 5/20\n",
      " - 18s - loss: 145.4554 - val_loss: 142.9963\n",
      "Epoch 6/20\n",
      " - 18s - loss: 145.4607 - val_loss: 146.2435\n",
      "Epoch 7/20\n",
      " - 18s - loss: 145.4623 - val_loss: 144.2334\n",
      "Epoch 8/20\n",
      " - 18s - loss: 145.4603 - val_loss: 144.3911\n",
      "Epoch 9/20\n",
      " - 18s - loss: 145.4554 - val_loss: 146.2790\n",
      "Epoch 10/20\n",
      " - 18s - loss: 145.4553 - val_loss: 144.3616\n",
      "Epoch 11/20\n",
      " - 18s - loss: 145.4541 - val_loss: 145.6074\n",
      "Epoch 12/20\n",
      " - 18s - loss: 145.4527 - val_loss: 145.0064\n",
      "Epoch 13/20\n",
      " - 18s - loss: 145.4532 - val_loss: 144.9848\n",
      "Epoch 14/20\n",
      " - 18s - loss: 145.4520 - val_loss: 144.4532\n",
      "Epoch 15/20\n",
      " - 18s - loss: 145.4514 - val_loss: 145.2496\n",
      "Epoch 16/20\n",
      " - 18s - loss: 145.4513 - val_loss: 145.9291\n",
      "Epoch 17/20\n",
      " - 18s - loss: 145.4521 - val_loss: 143.7548\n",
      "Epoch 18/20\n",
      " - 18s - loss: 145.4500 - val_loss: 145.8737\n",
      "Epoch 19/20\n",
      " - 18s - loss: 145.4504 - val_loss: 144.6277\n",
      "Epoch 20/20\n",
      " - 18s - loss: 145.4518 - val_loss: 143.4410\n",
      "Test accuracy: 143.44096549479167\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 6086.8065 - val_loss: 6043.3283\n",
      "Epoch 2/20\n",
      " - 12s - loss: 6043.2428 - val_loss: 6043.0969\n",
      "Epoch 3/20\n",
      " - 12s - loss: 6043.2359 - val_loss: 6043.3225\n",
      "Epoch 4/20\n",
      " - 12s - loss: 6043.2341 - val_loss: 6043.2568\n",
      "Epoch 5/20\n",
      " - 12s - loss: 6043.2305 - val_loss: 6042.9700\n",
      "Epoch 6/20\n",
      " - 12s - loss: 6043.2274 - val_loss: 6043.5174\n",
      "Epoch 7/20\n",
      " - 12s - loss: 6043.2251 - val_loss: 6042.9224\n",
      "Epoch 8/20\n",
      " - 12s - loss: 6043.2230 - val_loss: 6043.0774\n",
      "Epoch 9/20\n",
      " - 12s - loss: 6043.2223 - val_loss: 6042.8972\n",
      "Epoch 10/20\n",
      " - 12s - loss: 6043.2204 - val_loss: 6043.5108\n",
      "Epoch 11/20\n",
      " - 12s - loss: 6043.2202 - val_loss: 6042.9286\n",
      "Epoch 12/20\n",
      " - 12s - loss: 6043.2187 - val_loss: 6043.3749\n",
      "Epoch 13/20\n",
      " - 12s - loss: 6043.2178 - val_loss: 6043.0825\n",
      "Epoch 14/20\n",
      " - 12s - loss: 6043.2173 - val_loss: 6043.2998\n",
      "Epoch 15/20\n",
      " - 12s - loss: 6043.2170 - val_loss: 6043.1466\n",
      "Epoch 16/20\n",
      " - 12s - loss: 6043.2163 - val_loss: 6043.0534\n",
      "Epoch 17/20\n",
      " - 12s - loss: 6043.2161 - val_loss: 6043.5238\n",
      "Epoch 18/20\n",
      " - 12s - loss: 6043.2152 - val_loss: 6043.0998\n",
      "Epoch 19/20\n",
      " - 12s - loss: 6043.2152 - val_loss: 6043.5916\n",
      "Epoch 20/20\n",
      " - 12s - loss: 6043.2151 - val_loss: 6043.3503\n",
      "Test accuracy: 6043.350302864584\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 6028.5086 - val_loss: 5971.0189\n",
      "Epoch 2/20\n",
      " - 12s - loss: 5979.0916 - val_loss: 5973.4795\n",
      "Epoch 3/20\n",
      " - 12s - loss: 5978.9181 - val_loss: 5970.4993\n",
      "Epoch 4/20\n",
      " - 12s - loss: 5976.6550 - val_loss: 6002.0978\n",
      "Epoch 5/20\n",
      " - 12s - loss: 5977.4614 - val_loss: 5971.3347\n",
      "Epoch 6/20\n",
      " - 12s - loss: 5975.6802 - val_loss: 5970.6628\n",
      "Epoch 7/20\n",
      " - 12s - loss: 5976.3525 - val_loss: 5970.1490\n",
      "Epoch 8/20\n",
      " - 12s - loss: 5974.9299 - val_loss: 5971.2548\n",
      "Epoch 9/20\n",
      " - 12s - loss: 5974.4800 - val_loss: 5970.7016\n",
      "Epoch 10/20\n",
      " - 12s - loss: 5974.2916 - val_loss: 5971.3510\n",
      "Epoch 11/20\n",
      " - 12s - loss: 5973.6413 - val_loss: 5971.7553\n",
      "Epoch 12/20\n",
      " - 12s - loss: 5972.4668 - val_loss: 5971.1164\n",
      "Epoch 13/20\n",
      " - 12s - loss: 5976.7854 - val_loss: 5970.9353\n",
      "Epoch 14/20\n",
      " - 12s - loss: 5973.0391 - val_loss: 5971.1858\n",
      "Epoch 15/20\n",
      " - 12s - loss: 5974.0513 - val_loss: 5971.1865\n",
      "Epoch 16/20\n",
      " - 12s - loss: 5972.1635 - val_loss: 5971.0905\n",
      "Epoch 17/20\n",
      " - 12s - loss: 5973.3118 - val_loss: 5996.5201\n",
      "Epoch 18/20\n",
      " - 12s - loss: 5974.0877 - val_loss: 5972.7622\n",
      "Epoch 19/20\n",
      " - 12s - loss: 5980.0584 - val_loss: 5971.3297\n",
      "Epoch 20/20\n",
      " - 12s - loss: 5975.4917 - val_loss: 5971.1755\n",
      "Test accuracy: 5971.17556875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 6149.6957 - val_loss: 6106.3682\n",
      "Epoch 2/20\n",
      " - 12s - loss: 6106.0539 - val_loss: 6105.8584\n",
      "Epoch 3/20\n",
      " - 12s - loss: 6106.0394 - val_loss: 6105.9288\n",
      "Epoch 4/20\n",
      " - 12s - loss: 6106.0358 - val_loss: 6106.0740\n",
      "Epoch 5/20\n",
      " - 12s - loss: 6106.0349 - val_loss: 6106.2055\n",
      "Epoch 6/20\n",
      " - 12s - loss: 6106.0344 - val_loss: 6105.7672\n",
      "Epoch 7/20\n",
      " - 12s - loss: 6106.0342 - val_loss: 6105.8789\n",
      "Epoch 8/20\n",
      " - 12s - loss: 6106.0337 - val_loss: 6105.9618\n",
      "Epoch 9/20\n",
      " - 12s - loss: 6106.0333 - val_loss: 6106.0692\n",
      "Epoch 10/20\n",
      " - 12s - loss: 6106.0340 - val_loss: 6105.9874\n",
      "Epoch 11/20\n",
      " - 12s - loss: 6106.0330 - val_loss: 6106.1473\n",
      "Epoch 12/20\n",
      " - 12s - loss: 6106.0332 - val_loss: 6105.8914\n",
      "Epoch 13/20\n",
      " - 12s - loss: 6106.0333 - val_loss: 6106.0026\n",
      "Epoch 14/20\n",
      " - 12s - loss: 6106.0328 - val_loss: 6106.0417\n",
      "Epoch 15/20\n",
      " - 12s - loss: 6106.0326 - val_loss: 6105.9548\n",
      "Epoch 16/20\n",
      " - 12s - loss: 6106.0322 - val_loss: 6105.9424\n",
      "Epoch 17/20\n",
      " - 12s - loss: 6106.0324 - val_loss: 6106.0493\n",
      "Epoch 18/20\n",
      " - 12s - loss: 6106.0321 - val_loss: 6105.9967\n",
      "Epoch 19/20\n",
      " - 12s - loss: 6106.0315 - val_loss: 6106.0148\n",
      "Epoch 20/20\n",
      " - 12s - loss: 6106.0318 - val_loss: 6106.1341\n",
      "Test accuracy: 6106.1340609375\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 4689.1649 - val_loss: 4647.8606\n",
      "Epoch 2/20\n",
      " - 12s - loss: 4647.1829 - val_loss: 4647.6856\n",
      "Epoch 3/20\n",
      " - 12s - loss: 4647.1732 - val_loss: 4647.1337\n",
      "Epoch 4/20\n",
      " - 12s - loss: 4647.1656 - val_loss: 4647.1357\n",
      "Epoch 5/20\n",
      " - 12s - loss: 4647.1608 - val_loss: 4646.5327\n",
      "Epoch 6/20\n",
      " - 12s - loss: 4647.1560 - val_loss: 4647.0117\n",
      "Epoch 7/20\n",
      " - 12s - loss: 4647.1529 - val_loss: 4647.0432\n",
      "Epoch 8/20\n",
      " - 12s - loss: 4647.1509 - val_loss: 4647.5322\n",
      "Epoch 9/20\n",
      " - 12s - loss: 4647.1491 - val_loss: 4646.4963\n",
      "Epoch 10/20\n",
      " - 12s - loss: 4647.1469 - val_loss: 4647.6461\n",
      "Epoch 11/20\n",
      " - 12s - loss: 4647.1464 - val_loss: 4646.8308\n",
      "Epoch 12/20\n",
      " - 12s - loss: 4647.1448 - val_loss: 4646.7908\n",
      "Epoch 13/20\n",
      " - 12s - loss: 4647.1438 - val_loss: 4647.2354\n",
      "Epoch 14/20\n",
      " - 12s - loss: 4647.1428 - val_loss: 4647.2625\n",
      "Epoch 15/20\n",
      " - 12s - loss: 4647.1426 - val_loss: 4647.0495\n",
      "Epoch 16/20\n",
      " - 12s - loss: 4647.1416 - val_loss: 4647.3161\n",
      "Epoch 17/20\n",
      " - 12s - loss: 4647.1408 - val_loss: 4647.5527\n",
      "Epoch 18/20\n",
      " - 12s - loss: 4647.1410 - val_loss: 4647.3962\n",
      "Epoch 19/20\n",
      " - 13s - loss: 4647.1408 - val_loss: 4647.2430\n",
      "Epoch 20/20\n",
      " - 12s - loss: 4647.1404 - val_loss: 4646.9424\n",
      "Test accuracy: 4646.9423875\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 5263.6524 - val_loss: 5220.0859\n",
      "Epoch 2/20\n",
      " - 12s - loss: 5219.9375 - val_loss: 5220.0748\n",
      "Epoch 3/20\n",
      " - 12s - loss: 5219.9366 - val_loss: 5219.5591\n",
      "Epoch 4/20\n",
      " - 12s - loss: 5219.9357 - val_loss: 5219.9899\n",
      "Epoch 5/20\n",
      " - 12s - loss: 5219.9351 - val_loss: 5220.0161\n",
      "Epoch 6/20\n",
      " - 12s - loss: 5219.9350 - val_loss: 5219.6447\n",
      "Epoch 7/20\n",
      " - 12s - loss: 5219.9351 - val_loss: 5219.5305\n",
      "Epoch 8/20\n",
      " - 12s - loss: 5219.9343 - val_loss: 5220.1457\n",
      "Epoch 9/20\n",
      " - 12s - loss: 5219.9344 - val_loss: 5220.1020\n",
      "Epoch 10/20\n",
      " - 12s - loss: 5219.9338 - val_loss: 5219.7883\n",
      "Epoch 11/20\n",
      " - 12s - loss: 5219.9335 - val_loss: 5219.8776\n",
      "Epoch 12/20\n",
      " - 13s - loss: 5219.9330 - val_loss: 5219.8921\n",
      "Epoch 13/20\n",
      " - 12s - loss: 5219.9326 - val_loss: 5219.9576\n",
      "Epoch 14/20\n",
      " - 12s - loss: 5219.9323 - val_loss: 5220.0317\n",
      "Epoch 15/20\n",
      " - 12s - loss: 5219.9322 - val_loss: 5219.9508\n",
      "Epoch 16/20\n",
      " - 12s - loss: 5219.9314 - val_loss: 5219.8587\n",
      "Epoch 17/20\n",
      " - 12s - loss: 5219.9313 - val_loss: 5220.4700\n",
      "Epoch 18/20\n",
      " - 12s - loss: 5219.9308 - val_loss: 5219.6405\n",
      "Epoch 19/20\n",
      " - 12s - loss: 5219.9310 - val_loss: 5219.7037\n",
      "Epoch 20/20\n",
      " - 13s - loss: 5219.9305 - val_loss: 5219.5342\n",
      "Test accuracy: 5219.534153645834\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 4512.1534 - val_loss: 4468.7343\n",
      "Epoch 2/20\n",
      " - 13s - loss: 4468.8944 - val_loss: 4468.9780\n",
      "Epoch 3/20\n",
      " - 12s - loss: 4468.8885 - val_loss: 4468.7675\n",
      "Epoch 4/20\n",
      " - 12s - loss: 4468.8849 - val_loss: 4469.0154\n",
      "Epoch 5/20\n",
      " - 12s - loss: 4468.8817 - val_loss: 4468.8487\n",
      "Epoch 6/20\n",
      " - 13s - loss: 4468.8790 - val_loss: 4468.8595\n",
      "Epoch 7/20\n",
      " - 13s - loss: 4468.8779 - val_loss: 4469.0647\n",
      "Epoch 8/20\n",
      " - 13s - loss: 4468.8761 - val_loss: 4468.6258\n",
      "Epoch 9/20\n",
      " - 12s - loss: 4468.8751 - val_loss: 4468.8306\n",
      "Epoch 10/20\n",
      " - 12s - loss: 4468.8741 - val_loss: 4468.9939\n",
      "Epoch 11/20\n",
      " - 13s - loss: 4468.8736 - val_loss: 4468.7821\n",
      "Epoch 12/20\n",
      " - 12s - loss: 4468.8720 - val_loss: 4468.9892\n",
      "Epoch 13/20\n",
      " - 12s - loss: 4468.8718 - val_loss: 4468.8583\n",
      "Epoch 14/20\n",
      " - 12s - loss: 4468.8710 - val_loss: 4468.9224\n",
      "Epoch 15/20\n",
      " - 12s - loss: 4468.8707 - val_loss: 4468.7921\n",
      "Epoch 16/20\n",
      " - 13s - loss: 4468.8698 - val_loss: 4468.7272\n",
      "Epoch 17/20\n",
      " - 13s - loss: 4468.8697 - val_loss: 4468.8216\n",
      "Epoch 18/20\n",
      " - 12s - loss: 4468.8690 - val_loss: 4468.9285\n",
      "Epoch 19/20\n",
      " - 12s - loss: 4468.8690 - val_loss: 4468.9020\n",
      "Epoch 20/20\n",
      " - 13s - loss: 4468.8687 - val_loss: 4468.9589\n",
      "Test accuracy: 4468.9589203125\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 6238.0890 - val_loss: 6194.6131\n",
      "Epoch 2/20\n",
      " - 12s - loss: 6194.4136 - val_loss: 6194.0940\n",
      "Epoch 3/20\n",
      " - 13s - loss: 6194.4086 - val_loss: 6195.0210\n",
      "Epoch 4/20\n",
      " - 13s - loss: 6194.4056 - val_loss: 6194.1730\n",
      "Epoch 5/20\n",
      " - 13s - loss: 6194.4037 - val_loss: 6194.8247\n",
      "Epoch 6/20\n",
      " - 13s - loss: 6194.4017 - val_loss: 6194.3633\n",
      "Epoch 7/20\n",
      " - 12s - loss: 6194.4001 - val_loss: 6194.4675\n",
      "Epoch 8/20\n",
      " - 12s - loss: 6194.3982 - val_loss: 6194.6091\n",
      "Epoch 9/20\n",
      " - 13s - loss: 6194.3975 - val_loss: 6194.5547\n",
      "Epoch 10/20\n",
      " - 13s - loss: 6194.3958 - val_loss: 6193.9338\n",
      "Epoch 11/20\n",
      " - 12s - loss: 6194.3948 - val_loss: 6195.0157\n",
      "Epoch 12/20\n",
      " - 12s - loss: 6194.3945 - val_loss: 6194.4417\n",
      "Epoch 13/20\n",
      " - 12s - loss: 6194.3933 - val_loss: 6194.7849\n",
      "Epoch 14/20\n",
      " - 12s - loss: 6194.3934 - val_loss: 6194.6487\n",
      "Epoch 15/20\n",
      " - 12s - loss: 6194.3925 - val_loss: 6194.2935\n",
      "Epoch 16/20\n",
      " - 12s - loss: 6194.3916 - val_loss: 6194.2793\n",
      "Epoch 17/20\n",
      " - 12s - loss: 6194.3915 - val_loss: 6194.1052\n",
      "Epoch 18/20\n",
      " - 12s - loss: 6194.3904 - val_loss: 6194.0094\n",
      "Epoch 19/20\n",
      " - 12s - loss: 6194.3904 - val_loss: 6194.3680\n",
      "Epoch 20/20\n",
      " - 12s - loss: 6194.3899 - val_loss: 6194.4677\n",
      "Test accuracy: 6194.467640885417\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 1863.5895 - val_loss: 1820.2124\n",
      "Epoch 2/20\n",
      " - 12s - loss: 1820.1551 - val_loss: 1820.1984\n",
      "Epoch 3/20\n",
      " - 12s - loss: 1820.1524 - val_loss: 1820.1842\n",
      "Epoch 4/20\n",
      " - 12s - loss: 1820.1515 - val_loss: 1820.2831\n",
      "Epoch 5/20\n",
      " - 12s - loss: 1820.1507 - val_loss: 1820.0648\n",
      "Epoch 6/20\n",
      " - 12s - loss: 1820.1498 - val_loss: 1820.1211\n",
      "Epoch 7/20\n",
      " - 12s - loss: 1820.1493 - val_loss: 1820.1724\n",
      "Epoch 8/20\n",
      " - 12s - loss: 1820.1485 - val_loss: 1820.0567\n",
      "Epoch 9/20\n",
      " - 13s - loss: 1820.1481 - val_loss: 1820.0919\n",
      "Epoch 10/20\n",
      " - 12s - loss: 1820.1475 - val_loss: 1820.1673\n",
      "Epoch 11/20\n",
      " - 12s - loss: 1820.1474 - val_loss: 1820.1389\n",
      "Epoch 12/20\n",
      " - 12s - loss: 1820.1469 - val_loss: 1820.0845\n",
      "Epoch 13/20\n",
      " - 12s - loss: 1820.1462 - val_loss: 1820.0555\n",
      "Epoch 14/20\n",
      " - 12s - loss: 1820.1461 - val_loss: 1820.1393\n",
      "Epoch 15/20\n",
      " - 12s - loss: 1820.1456 - val_loss: 1820.1779\n",
      "Epoch 16/20\n",
      " - 12s - loss: 1820.1454 - val_loss: 1820.0583\n",
      "Epoch 17/20\n",
      " - 12s - loss: 1820.1449 - val_loss: 1820.2079\n",
      "Epoch 18/20\n",
      " - 12s - loss: 1820.1446 - val_loss: 1820.0821\n",
      "Epoch 19/20\n",
      " - 12s - loss: 1820.1444 - val_loss: 1820.1195\n",
      "Epoch 20/20\n",
      " - 12s - loss: 1820.1439 - val_loss: 1820.1185\n",
      "Test accuracy: 1820.1185192057292\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 3087.1802 - val_loss: 3043.3062\n",
      "Epoch 2/20\n",
      " - 12s - loss: 3043.1513 - val_loss: 3043.0484\n",
      "Epoch 3/20\n",
      " - 12s - loss: 3043.1494 - val_loss: 3042.9869\n",
      "Epoch 4/20\n",
      " - 12s - loss: 3043.1469 - val_loss: 3043.0664\n",
      "Epoch 5/20\n",
      " - 12s - loss: 3043.1460 - val_loss: 3042.7328\n",
      "Epoch 6/20\n",
      " - 12s - loss: 3043.1454 - val_loss: 3043.2409\n",
      "Epoch 7/20\n",
      " - 12s - loss: 3043.1443 - val_loss: 3043.2764\n",
      "Epoch 8/20\n",
      " - 12s - loss: 3043.1432 - val_loss: 3043.2491\n",
      "Epoch 9/20\n",
      " - 12s - loss: 3043.1428 - val_loss: 3043.3165\n",
      "Epoch 10/20\n",
      " - 12s - loss: 3043.1424 - val_loss: 3043.1629\n",
      "Epoch 11/20\n",
      " - 12s - loss: 3043.1418 - val_loss: 3043.1991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      " - 12s - loss: 3043.1413 - val_loss: 3043.2327\n",
      "Epoch 13/20\n",
      " - 12s - loss: 3043.1409 - val_loss: 3043.3760\n",
      "Epoch 14/20\n",
      " - 12s - loss: 3043.1406 - val_loss: 3043.0926\n",
      "Epoch 15/20\n",
      " - 12s - loss: 3043.1401 - val_loss: 3043.3172\n",
      "Epoch 16/20\n",
      " - 13s - loss: 3043.1395 - val_loss: 3043.0856\n",
      "Epoch 17/20\n",
      " - 12s - loss: 3043.1398 - val_loss: 3043.0251\n",
      "Epoch 18/20\n",
      " - 12s - loss: 3043.1391 - val_loss: 3042.7923\n",
      "Epoch 19/20\n",
      " - 12s - loss: 3043.1389 - val_loss: 3043.1425\n",
      "Epoch 20/20\n",
      " - 12s - loss: 3043.1386 - val_loss: 3043.1928\n",
      "Test accuracy: 3043.1928397135416\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 4023.8509 - val_loss: 3980.2938\n",
      "Epoch 2/20\n",
      " - 12s - loss: 3980.2888 - val_loss: 3980.2680\n",
      "Epoch 3/20\n",
      " - 12s - loss: 3980.2873 - val_loss: 3980.1545\n",
      "Epoch 4/20\n",
      " - 12s - loss: 3980.2866 - val_loss: 3980.3125\n",
      "Epoch 5/20\n",
      " - 12s - loss: 3980.2863 - val_loss: 3980.2797\n",
      "Epoch 6/20\n",
      " - 12s - loss: 3980.2853 - val_loss: 3980.1908\n",
      "Epoch 7/20\n",
      " - 12s - loss: 3980.2849 - val_loss: 3980.1197\n",
      "Epoch 8/20\n",
      " - 12s - loss: 3980.2852 - val_loss: 3980.2132\n",
      "Epoch 9/20\n",
      " - 12s - loss: 3980.2849 - val_loss: 3980.2790\n",
      "Epoch 10/20\n",
      " - 12s - loss: 3980.2845 - val_loss: 3980.3068\n",
      "Epoch 11/20\n",
      " - 12s - loss: 3980.2847 - val_loss: 3980.5704\n",
      "Epoch 12/20\n",
      " - 12s - loss: 3980.2843 - val_loss: 3980.3670\n",
      "Epoch 13/20\n",
      " - 12s - loss: 3980.2837 - val_loss: 3980.3270\n",
      "Epoch 14/20\n",
      " - 12s - loss: 3980.2838 - val_loss: 3980.3000\n",
      "Epoch 15/20\n",
      " - 12s - loss: 3980.2836 - val_loss: 3980.4054\n",
      "Epoch 16/20\n",
      " - 12s - loss: 3980.2835 - val_loss: 3980.2250\n",
      "Epoch 17/20\n",
      " - 12s - loss: 3980.2833 - val_loss: 3980.1910\n",
      "Epoch 18/20\n",
      " - 12s - loss: 3980.2831 - val_loss: 3980.1172\n",
      "Epoch 19/20\n",
      " - 12s - loss: 3980.2827 - val_loss: 3980.5792\n",
      "Epoch 20/20\n",
      " - 13s - loss: 3980.2828 - val_loss: 3980.4290\n",
      "Test accuracy: 3980.429035546875\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 2718.7632 - val_loss: 2677.3099\n",
      "Epoch 2/20\n",
      " - 12s - loss: 2677.8565 - val_loss: 2678.1041\n",
      "Epoch 3/20\n",
      " - 12s - loss: 2677.8225 - val_loss: 2677.5302\n",
      "Epoch 4/20\n",
      " - 12s - loss: 2677.8091 - val_loss: 2677.8088\n",
      "Epoch 5/20\n",
      " - 13s - loss: 2677.8037 - val_loss: 2677.8138\n",
      "Epoch 6/20\n",
      " - 12s - loss: 2677.8013 - val_loss: 2677.8048\n",
      "Epoch 7/20\n",
      " - 12s - loss: 2677.8001 - val_loss: 2677.7434\n",
      "Epoch 8/20\n",
      " - 12s - loss: 2677.7999 - val_loss: 2677.8206\n",
      "Epoch 9/20\n",
      " - 12s - loss: 2677.7996 - val_loss: 2677.7894\n",
      "Epoch 10/20\n",
      " - 13s - loss: 2677.7991 - val_loss: 2677.7183\n",
      "Epoch 11/20\n",
      " - 12s - loss: 2677.7991 - val_loss: 2677.8882\n",
      "Epoch 12/20\n",
      " - 12s - loss: 2677.7988 - val_loss: 2677.8143\n",
      "Epoch 13/20\n",
      " - 12s - loss: 2677.7993 - val_loss: 2677.8472\n",
      "Epoch 14/20\n",
      " - 12s - loss: 2677.7991 - val_loss: 2677.6588\n",
      "Epoch 15/20\n",
      " - 13s - loss: 2677.7991 - val_loss: 2677.8103\n",
      "Epoch 16/20\n",
      " - 12s - loss: 2677.7991 - val_loss: 2677.7888\n",
      "Epoch 17/20\n",
      " - 12s - loss: 2677.7992 - val_loss: 2677.7403\n",
      "Epoch 18/20\n",
      " - 12s - loss: 2677.7989 - val_loss: 2677.7486\n",
      "Epoch 19/20\n",
      " - 12s - loss: 2677.7986 - val_loss: 2677.8230\n",
      "Epoch 20/20\n",
      " - 12s - loss: 2677.7983 - val_loss: 2677.7000\n",
      "Test accuracy: 2677.699974609375\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 15s - loss: 1439.2229 - val_loss: 1416.6838\n",
      "Epoch 2/20\n",
      " - 10s - loss: 1416.7177 - val_loss: 1416.7183\n",
      "Epoch 3/20\n",
      " - 10s - loss: 1416.7171 - val_loss: 1416.6654\n",
      "Epoch 4/20\n",
      " - 10s - loss: 1416.7175 - val_loss: 1416.6395\n",
      "Epoch 5/20\n",
      " - 10s - loss: 1416.7169 - val_loss: 1416.6536\n",
      "Epoch 6/20\n",
      " - 10s - loss: 1416.7170 - val_loss: 1416.6601\n",
      "Epoch 7/20\n",
      " - 10s - loss: 1416.7163 - val_loss: 1416.8068\n",
      "Epoch 8/20\n",
      " - 10s - loss: 1416.7164 - val_loss: 1416.6564\n",
      "Epoch 9/20\n",
      " - 10s - loss: 1416.7156 - val_loss: 1416.7096\n",
      "Epoch 10/20\n",
      " - 10s - loss: 1416.7160 - val_loss: 1416.6519\n",
      "Epoch 11/20\n",
      " - 10s - loss: 1416.7160 - val_loss: 1416.7380\n",
      "Epoch 12/20\n",
      " - 10s - loss: 1416.7159 - val_loss: 1416.4809\n",
      "Epoch 13/20\n",
      " - 10s - loss: 1416.7155 - val_loss: 1416.8714\n",
      "Epoch 14/20\n",
      " - 10s - loss: 1416.7151 - val_loss: 1416.8241\n",
      "Epoch 15/20\n",
      " - 10s - loss: 1416.7152 - val_loss: 1416.7477\n",
      "Epoch 16/20\n",
      " - 10s - loss: 1416.7148 - val_loss: 1416.4865\n",
      "Epoch 17/20\n",
      " - 10s - loss: 1416.7150 - val_loss: 1416.6268\n",
      "Epoch 18/20\n",
      " - 10s - loss: 1416.7146 - val_loss: 1416.6523\n",
      "Epoch 19/20\n",
      " - 10s - loss: 1416.7147 - val_loss: 1416.7433\n",
      "Epoch 20/20\n",
      " - 10s - loss: 1416.7148 - val_loss: 1416.6020\n",
      "Test accuracy: 1416.601953515625\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 4743.1864 - val_loss: 4699.6184\n",
      "Epoch 2/20\n",
      " - 13s - loss: 4699.3710 - val_loss: 4699.0005\n",
      "Epoch 3/20\n",
      " - 13s - loss: 4699.3634 - val_loss: 4698.7479\n",
      "Epoch 4/20\n",
      " - 13s - loss: 4699.3593 - val_loss: 4698.6381\n",
      "Epoch 5/20\n",
      " - 13s - loss: 4699.3542 - val_loss: 4699.3924\n",
      "Epoch 6/20\n",
      " - 12s - loss: 4699.3514 - val_loss: 4699.3841\n",
      "Epoch 7/20\n",
      " - 13s - loss: 4699.3479 - val_loss: 4699.3323\n",
      "Epoch 8/20\n",
      " - 12s - loss: 4699.3455 - val_loss: 4699.3430\n",
      "Epoch 9/20\n",
      " - 13s - loss: 4699.3438 - val_loss: 4699.1963\n",
      "Epoch 10/20\n",
      " - 13s - loss: 4699.3420 - val_loss: 4699.5191\n",
      "Epoch 11/20\n",
      " - 13s - loss: 4699.3406 - val_loss: 4698.9837\n",
      "Epoch 12/20\n",
      " - 12s - loss: 4699.3389 - val_loss: 4698.9061\n",
      "Epoch 13/20\n",
      " - 13s - loss: 4699.3387 - val_loss: 4699.1333\n",
      "Epoch 14/20\n",
      " - 13s - loss: 4699.3371 - val_loss: 4699.6143\n",
      "Epoch 15/20\n",
      " - 13s - loss: 4699.3369 - val_loss: 4699.5753\n",
      "Epoch 16/20\n",
      " - 13s - loss: 4699.3360 - val_loss: 4699.2441\n",
      "Epoch 17/20\n",
      " - 13s - loss: 4699.3358 - val_loss: 4698.8680\n",
      "Epoch 18/20\n",
      " - 13s - loss: 4699.3347 - val_loss: 4699.5012\n",
      "Epoch 19/20\n",
      " - 13s - loss: 4699.3347 - val_loss: 4699.1683\n",
      "Epoch 20/20\n",
      " - 13s - loss: 4699.3336 - val_loss: 4699.3350\n",
      "Test accuracy: 4699.33498515625\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 1992.2105 - val_loss: 1956.1507\n",
      "Epoch 2/20\n",
      " - 11s - loss: 1956.2022 - val_loss: 1956.2898\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1956.1983 - val_loss: 1956.1244\n",
      "Epoch 4/20\n",
      " - 11s - loss: 1956.1969 - val_loss: 1956.2313\n",
      "Epoch 5/20\n",
      " - 11s - loss: 1956.1955 - val_loss: 1956.2447\n",
      "Epoch 6/20\n",
      " - 11s - loss: 1956.1937 - val_loss: 1956.1399\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1956.1928 - val_loss: 1956.2745\n",
      "Epoch 8/20\n",
      " - 11s - loss: 1956.1918 - val_loss: 1956.1383\n",
      "Epoch 9/20\n",
      " - 11s - loss: 1956.1907 - val_loss: 1956.1280\n",
      "Epoch 10/20\n",
      " - 11s - loss: 1956.1902 - val_loss: 1956.1295\n",
      "Epoch 11/20\n",
      " - 11s - loss: 1956.1889 - val_loss: 1956.1803\n",
      "Epoch 12/20\n",
      " - 11s - loss: 1956.1884 - val_loss: 1956.2205\n",
      "Epoch 13/20\n",
      " - 11s - loss: 1956.1881 - val_loss: 1956.2865\n",
      "Epoch 14/20\n",
      " - 11s - loss: 1956.1874 - val_loss: 1956.1830\n",
      "Epoch 15/20\n",
      " - 11s - loss: 1956.1866 - val_loss: 1956.1543\n",
      "Epoch 16/20\n",
      " - 11s - loss: 1956.1864 - val_loss: 1956.1856\n",
      "Epoch 17/20\n",
      " - 11s - loss: 1956.1858 - val_loss: 1956.1352\n",
      "Epoch 18/20\n",
      " - 11s - loss: 1956.1855 - val_loss: 1956.1948\n",
      "Epoch 19/20\n",
      " - 11s - loss: 1956.1851 - val_loss: 1956.1686\n",
      "Epoch 20/20\n",
      " - 11s - loss: 1956.1845 - val_loss: 1956.1371\n",
      "Test accuracy: 1956.1371151041667\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 3392.7367 - val_loss: 3349.8369\n",
      "Epoch 2/20\n",
      " - 13s - loss: 3349.4879 - val_loss: 3349.5443\n",
      "Epoch 3/20\n",
      " - 13s - loss: 3349.4857 - val_loss: 3349.5453\n",
      "Epoch 4/20\n",
      " - 13s - loss: 3349.4848 - val_loss: 3349.5726\n",
      "Epoch 5/20\n",
      " - 13s - loss: 3349.4842 - val_loss: 3349.7626\n",
      "Epoch 6/20\n",
      " - 13s - loss: 3349.4836 - val_loss: 3349.5909\n",
      "Epoch 7/20\n",
      " - 13s - loss: 3349.4826 - val_loss: 3349.4789\n",
      "Epoch 8/20\n",
      " - 13s - loss: 3349.4829 - val_loss: 3349.6616\n",
      "Epoch 9/20\n",
      " - 13s - loss: 3349.4818 - val_loss: 3349.3873\n",
      "Epoch 10/20\n",
      " - 13s - loss: 3349.4818 - val_loss: 3349.4915\n",
      "Epoch 11/20\n",
      " - 13s - loss: 3349.4815 - val_loss: 3349.6224\n",
      "Epoch 12/20\n",
      " - 13s - loss: 3349.4812 - val_loss: 3349.4751\n",
      "Epoch 13/20\n",
      " - 13s - loss: 3349.4809 - val_loss: 3349.5777\n",
      "Epoch 14/20\n",
      " - 13s - loss: 3349.4806 - val_loss: 3349.4455\n",
      "Epoch 15/20\n",
      " - 13s - loss: 3349.4807 - val_loss: 3349.7017\n",
      "Epoch 16/20\n",
      " - 13s - loss: 3349.4800 - val_loss: 3349.6412\n",
      "Epoch 17/20\n",
      " - 13s - loss: 3349.4802 - val_loss: 3349.0979\n",
      "Epoch 18/20\n",
      " - 13s - loss: 3349.4799 - val_loss: 3349.3242\n",
      "Epoch 19/20\n",
      " - 13s - loss: 3349.4798 - val_loss: 3349.9079\n",
      "Epoch 20/20\n",
      " - 13s - loss: 3349.4797 - val_loss: 3349.2967\n",
      "Test accuracy: 3349.2967532552084\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 10s - loss: 458.7888 - val_loss: 420.5089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      " - 5s - loss: 420.4808 - val_loss: 420.4460\n",
      "Epoch 3/20\n",
      " - 5s - loss: 420.4766 - val_loss: 420.5015\n",
      "Epoch 4/20\n",
      " - 5s - loss: 420.4749 - val_loss: 420.4888\n",
      "Epoch 5/20\n",
      " - 5s - loss: 420.4742 - val_loss: 420.4789\n",
      "Epoch 6/20\n",
      " - 5s - loss: 420.4731 - val_loss: 420.4898\n",
      "Epoch 7/20\n",
      " - 5s - loss: 420.4732 - val_loss: 420.5178\n",
      "Epoch 8/20\n",
      " - 5s - loss: 420.4729 - val_loss: 420.5283\n",
      "Epoch 9/20\n",
      " - 5s - loss: 420.4730 - val_loss: 420.5365\n",
      "Epoch 10/20\n",
      " - 5s - loss: 420.4727 - val_loss: 420.4310\n",
      "Epoch 11/20\n",
      " - 5s - loss: 420.4727 - val_loss: 420.4035\n",
      "Epoch 12/20\n",
      " - 5s - loss: 420.4722 - val_loss: 420.5027\n",
      "Epoch 13/20\n",
      " - 5s - loss: 420.4727 - val_loss: 420.4222\n",
      "Epoch 14/20\n",
      " - 5s - loss: 420.4721 - val_loss: 420.4709\n",
      "Epoch 15/20\n",
      " - 5s - loss: 420.4725 - val_loss: 420.5052\n",
      "Epoch 16/20\n",
      " - 5s - loss: 420.4726 - val_loss: 420.4213\n",
      "Epoch 17/20\n",
      " - 5s - loss: 420.4722 - val_loss: 420.4552\n",
      "Epoch 18/20\n",
      " - 5s - loss: 420.4719 - val_loss: 420.5102\n",
      "Epoch 19/20\n",
      " - 5s - loss: 420.4725 - val_loss: 420.4800\n",
      "Epoch 20/20\n",
      " - 5s - loss: 420.4720 - val_loss: 420.4720\n",
      "Test accuracy: 420.4720168294271\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 1085.7162 - val_loss: 1060.9925\n",
      "Epoch 2/20\n",
      " - 11s - loss: 1061.1410 - val_loss: 1060.9616\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1061.1226 - val_loss: 1061.2206\n",
      "Epoch 4/20\n",
      " - 11s - loss: 1061.1117 - val_loss: 1061.3226\n",
      "Epoch 5/20\n",
      " - 11s - loss: 1061.1007 - val_loss: 1061.3826\n",
      "Epoch 6/20\n",
      " - 11s - loss: 1061.0927 - val_loss: 1060.9410\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1061.0859 - val_loss: 1061.1756\n",
      "Epoch 8/20\n",
      " - 11s - loss: 1061.0816 - val_loss: 1061.1106\n",
      "Epoch 9/20\n",
      " - 11s - loss: 1061.0780 - val_loss: 1061.0724\n",
      "Epoch 10/20\n",
      " - 11s - loss: 1061.0735 - val_loss: 1060.8672\n",
      "Epoch 11/20\n",
      " - 11s - loss: 1061.0707 - val_loss: 1060.9854\n",
      "Epoch 12/20\n",
      " - 11s - loss: 1061.0683 - val_loss: 1061.2631\n",
      "Epoch 13/20\n",
      " - 11s - loss: 1061.0661 - val_loss: 1061.3042\n",
      "Epoch 14/20\n",
      " - 11s - loss: 1061.0652 - val_loss: 1060.9228\n",
      "Epoch 15/20\n",
      " - 11s - loss: 1061.0633 - val_loss: 1061.0717\n",
      "Epoch 16/20\n",
      " - 11s - loss: 1061.0624 - val_loss: 1061.3713\n",
      "Epoch 17/20\n",
      " - 11s - loss: 1061.0612 - val_loss: 1061.1023\n",
      "Epoch 18/20\n",
      " - 11s - loss: 1061.0604 - val_loss: 1061.1336\n",
      "Epoch 19/20\n",
      " - 11s - loss: 1061.0598 - val_loss: 1060.9706\n",
      "Epoch 20/20\n",
      " - 11s - loss: 1061.0595 - val_loss: 1061.1733\n",
      "Test accuracy: 1061.1733048177084\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 4965.5927 - val_loss: 4923.8015\n",
      "Epoch 2/20\n",
      " - 13s - loss: 4923.8334 - val_loss: 4923.7690\n",
      "Epoch 3/20\n",
      " - 13s - loss: 4923.8304 - val_loss: 4923.6630\n",
      "Epoch 4/20\n",
      " - 13s - loss: 4923.8284 - val_loss: 4923.8663\n",
      "Epoch 5/20\n",
      " - 13s - loss: 4923.8274 - val_loss: 4923.9199\n",
      "Epoch 6/20\n",
      " - 13s - loss: 4923.8261 - val_loss: 4923.9064\n",
      "Epoch 7/20\n",
      " - 13s - loss: 4923.8256 - val_loss: 4923.9241\n",
      "Epoch 8/20\n",
      " - 13s - loss: 4923.8244 - val_loss: 4923.9722\n",
      "Epoch 9/20\n",
      " - 13s - loss: 4923.8241 - val_loss: 4923.6393\n",
      "Epoch 10/20\n",
      " - 13s - loss: 4923.8236 - val_loss: 4923.7597\n",
      "Epoch 11/20\n",
      " - 13s - loss: 4923.8231 - val_loss: 4923.6611\n",
      "Epoch 12/20\n",
      " - 13s - loss: 4923.8225 - val_loss: 4923.5664\n",
      "Epoch 13/20\n",
      " - 13s - loss: 4923.8222 - val_loss: 4923.8867\n",
      "Epoch 14/20\n",
      " - 13s - loss: 4923.8218 - val_loss: 4923.7829\n",
      "Epoch 15/20\n",
      " - 13s - loss: 4923.8215 - val_loss: 4923.8672\n",
      "Epoch 16/20\n",
      " - 13s - loss: 4923.8213 - val_loss: 4923.9810\n",
      "Epoch 17/20\n",
      " - 13s - loss: 4923.8210 - val_loss: 4924.0849\n",
      "Epoch 18/20\n",
      " - 13s - loss: 4923.8210 - val_loss: 4923.8472\n",
      "Epoch 19/20\n",
      " - 13s - loss: 4923.8207 - val_loss: 4923.6810\n",
      "Epoch 20/20\n",
      " - 13s - loss: 4923.8197 - val_loss: 4923.7282\n",
      "Test accuracy: 4923.728223958334\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 249.5718 - val_loss: 146.3355\n",
      "Epoch 2/20\n",
      " - 12s - loss: 146.5077 - val_loss: 146.5300\n",
      "Epoch 3/20\n",
      " - 12s - loss: 146.5065 - val_loss: 146.4090\n",
      "Epoch 4/20\n",
      " - 12s - loss: 146.5059 - val_loss: 146.4733\n",
      "Epoch 5/20\n",
      " - 12s - loss: 146.5053 - val_loss: 146.4548\n",
      "Epoch 6/20\n",
      " - 12s - loss: 146.5051 - val_loss: 146.5245\n",
      "Epoch 7/20\n",
      " - 12s - loss: 146.5042 - val_loss: 146.5299\n",
      "Epoch 8/20\n",
      " - 12s - loss: 146.5041 - val_loss: 146.5278\n",
      "Epoch 9/20\n",
      " - 12s - loss: 146.5040 - val_loss: 146.5441\n",
      "Epoch 10/20\n",
      " - 12s - loss: 146.5037 - val_loss: 146.5349\n",
      "Epoch 11/20\n",
      " - 12s - loss: 146.5034 - val_loss: 146.5625\n",
      "Epoch 12/20\n",
      " - 12s - loss: 146.5038 - val_loss: 146.5119\n",
      "Epoch 13/20\n",
      " - 12s - loss: 146.5036 - val_loss: 146.4898\n",
      "Epoch 14/20\n",
      " - 12s - loss: 146.5035 - val_loss: 146.5271\n",
      "Epoch 15/20\n",
      " - 12s - loss: 146.5035 - val_loss: 146.5160\n",
      "Epoch 16/20\n",
      " - 12s - loss: 146.5033 - val_loss: 146.5345\n",
      "Epoch 17/20\n",
      " - 12s - loss: 146.5034 - val_loss: 146.5282\n",
      "Epoch 18/20\n",
      " - 12s - loss: 146.5038 - val_loss: 146.5482\n",
      "Epoch 19/20\n",
      " - 12s - loss: 146.5033 - val_loss: 146.5617\n",
      "Epoch 20/20\n",
      " - 12s - loss: 146.5035 - val_loss: 146.5445\n",
      "Test accuracy: 146.54454904785158\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 1217.6526 - val_loss: 1161.1860\n",
      "Epoch 2/20\n",
      " - 6s - loss: 1161.0590 - val_loss: 1161.0679\n",
      "Epoch 3/20\n",
      " - 6s - loss: 1161.0542 - val_loss: 1161.0217\n",
      "Epoch 4/20\n",
      " - 6s - loss: 1161.0521 - val_loss: 1161.0534\n",
      "Epoch 5/20\n",
      " - 6s - loss: 1161.0508 - val_loss: 1161.0231\n",
      "Epoch 6/20\n",
      " - 6s - loss: 1161.0504 - val_loss: 1161.0719\n",
      "Epoch 7/20\n",
      " - 6s - loss: 1161.0501 - val_loss: 1161.0103\n",
      "Epoch 8/20\n",
      " - 6s - loss: 1161.0498 - val_loss: 1161.0420\n",
      "Epoch 9/20\n",
      " - 6s - loss: 1161.0495 - val_loss: 1161.1632\n",
      "Epoch 10/20\n",
      " - 6s - loss: 1161.0496 - val_loss: 1161.0278\n",
      "Epoch 11/20\n",
      " - 6s - loss: 1161.0493 - val_loss: 1161.0187\n",
      "Epoch 12/20\n",
      " - 6s - loss: 1161.0495 - val_loss: 1161.0520\n",
      "Epoch 13/20\n",
      " - 6s - loss: 1161.0496 - val_loss: 1161.1147\n",
      "Epoch 14/20\n",
      " - 6s - loss: 1161.0488 - val_loss: 1161.1219\n",
      "Epoch 15/20\n",
      " - 6s - loss: 1161.0496 - val_loss: 1160.9988\n",
      "Epoch 16/20\n",
      " - 6s - loss: 1161.0491 - val_loss: 1161.1445\n",
      "Epoch 17/20\n",
      " - 6s - loss: 1161.0493 - val_loss: 1161.1275\n",
      "Epoch 18/20\n",
      " - 6s - loss: 1161.0490 - val_loss: 1161.0687\n",
      "Epoch 19/20\n",
      " - 6s - loss: 1161.0491 - val_loss: 1161.1162\n",
      "Epoch 20/20\n",
      " - 6s - loss: 1161.0492 - val_loss: 1161.0420\n",
      "Test accuracy: 1161.041951953125\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 882.4231 - val_loss: 859.6247\n",
      "Epoch 2/20\n",
      " - 11s - loss: 859.4849 - val_loss: 859.5911\n",
      "Epoch 3/20\n",
      " - 11s - loss: 859.4825 - val_loss: 859.5333\n",
      "Epoch 4/20\n",
      " - 11s - loss: 859.4818 - val_loss: 859.5038\n",
      "Epoch 5/20\n",
      " - 11s - loss: 859.4816 - val_loss: 859.4948\n",
      "Epoch 6/20\n",
      " - 11s - loss: 859.4816 - val_loss: 859.4923\n",
      "Epoch 7/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.4600\n",
      "Epoch 8/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.5167\n",
      "Epoch 9/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.5008\n",
      "Epoch 10/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.4906\n",
      "Epoch 11/20\n",
      " - 11s - loss: 859.4815 - val_loss: 859.4869\n",
      "Epoch 12/20\n",
      " - 11s - loss: 859.4815 - val_loss: 859.4611\n",
      "Epoch 13/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.5049\n",
      "Epoch 14/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.4762\n",
      "Epoch 15/20\n",
      " - 11s - loss: 859.4812 - val_loss: 859.4599\n",
      "Epoch 16/20\n",
      " - 11s - loss: 859.4814 - val_loss: 859.4924\n",
      "Epoch 17/20\n",
      " - 11s - loss: 859.4813 - val_loss: 859.4851\n",
      "Epoch 18/20\n",
      " - 11s - loss: 859.4813 - val_loss: 859.4755\n",
      "Epoch 19/20\n",
      " - 11s - loss: 859.4812 - val_loss: 859.5260\n",
      "Epoch 20/20\n",
      " - 11s - loss: 859.4813 - val_loss: 859.4590\n",
      "Test accuracy: 859.4589493164062\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 656.9469 - val_loss: 471.6737\n",
      "Epoch 2/20\n",
      " - 14s - loss: 471.9198 - val_loss: 471.8622\n",
      "Epoch 3/20\n",
      " - 14s - loss: 471.9188 - val_loss: 471.9379\n",
      "Epoch 4/20\n",
      " - 14s - loss: 471.9183 - val_loss: 471.9379\n",
      "Epoch 5/20\n",
      " - 13s - loss: 471.9180 - val_loss: 471.9411\n",
      "Epoch 6/20\n",
      " - 14s - loss: 471.9177 - val_loss: 471.9335\n",
      "Epoch 7/20\n",
      " - 13s - loss: 471.9176 - val_loss: 471.9407\n",
      "Epoch 8/20\n",
      " - 13s - loss: 471.9171 - val_loss: 471.9374\n",
      "Epoch 9/20\n",
      " - 13s - loss: 471.9171 - val_loss: 471.9340\n",
      "Epoch 10/20\n",
      " - 13s - loss: 471.9165 - val_loss: 471.9322\n",
      "Epoch 11/20\n",
      " - 13s - loss: 471.9167 - val_loss: 471.9366\n",
      "Epoch 12/20\n",
      " - 13s - loss: 471.9163 - val_loss: 471.9332\n",
      "Epoch 13/20\n",
      " - 13s - loss: 471.9161 - val_loss: 471.9379\n",
      "Epoch 14/20\n",
      " - 13s - loss: 471.9157 - val_loss: 471.9378\n",
      "Epoch 15/20\n",
      " - 13s - loss: 471.9155 - val_loss: 471.9352\n",
      "Epoch 16/20\n",
      " - 14s - loss: 471.9155 - val_loss: 471.9370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      " - 13s - loss: 471.9153 - val_loss: 471.9562\n",
      "Epoch 18/20\n",
      " - 13s - loss: 471.9153 - val_loss: 471.9441\n",
      "Epoch 19/20\n",
      " - 13s - loss: 471.9147 - val_loss: 471.9392\n",
      "Epoch 20/20\n",
      " - 13s - loss: 471.9152 - val_loss: 471.9306\n",
      "Test accuracy: 471.93059907226564\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 913.6342 - val_loss: 884.6340\n",
      "Epoch 2/20\n",
      " - 11s - loss: 884.6422 - val_loss: 884.6728\n",
      "Epoch 3/20\n",
      " - 11s - loss: 884.6422 - val_loss: 884.6226\n",
      "Epoch 4/20\n",
      " - 11s - loss: 884.6420 - val_loss: 884.5938\n",
      "Epoch 5/20\n",
      " - 11s - loss: 884.6418 - val_loss: 884.7244\n",
      "Epoch 6/20\n",
      " - 11s - loss: 884.6412 - val_loss: 884.5749\n",
      "Epoch 7/20\n",
      " - 11s - loss: 884.6414 - val_loss: 884.6631\n",
      "Epoch 8/20\n",
      " - 11s - loss: 884.6411 - val_loss: 884.6273\n",
      "Epoch 9/20\n",
      " - 11s - loss: 884.6412 - val_loss: 884.6917\n",
      "Epoch 10/20\n",
      " - 11s - loss: 884.6409 - val_loss: 884.6269\n",
      "Epoch 11/20\n",
      " - 11s - loss: 884.6406 - val_loss: 884.6182\n",
      "Epoch 12/20\n",
      " - 11s - loss: 884.6405 - val_loss: 884.5909\n",
      "Epoch 13/20\n",
      " - 11s - loss: 884.6404 - val_loss: 884.5865\n",
      "Epoch 14/20\n",
      " - 11s - loss: 884.6404 - val_loss: 884.6034\n",
      "Epoch 15/20\n",
      " - 11s - loss: 884.6403 - val_loss: 884.6616\n",
      "Epoch 16/20\n",
      " - 11s - loss: 884.6402 - val_loss: 884.6967\n",
      "Epoch 17/20\n",
      " - 11s - loss: 884.6402 - val_loss: 884.6133\n",
      "Epoch 18/20\n",
      " - 11s - loss: 884.6401 - val_loss: 884.6150\n",
      "Epoch 19/20\n",
      " - 11s - loss: 884.6399 - val_loss: 884.6218\n",
      "Epoch 20/20\n",
      " - 11s - loss: 884.6400 - val_loss: 884.6480\n",
      "Test accuracy: 884.6479576497396\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 2552.2353 - val_loss: 2491.3076\n",
      "Epoch 2/20\n",
      " - 6s - loss: 2491.3123 - val_loss: 2491.3072\n",
      "Epoch 3/20\n",
      " - 6s - loss: 2491.3098 - val_loss: 2491.3071\n",
      "Epoch 4/20\n",
      " - 6s - loss: 2491.3080 - val_loss: 2491.3069\n",
      "Epoch 5/20\n",
      " - 6s - loss: 2491.3070 - val_loss: 2491.3077\n",
      "Epoch 6/20\n",
      " - 6s - loss: 2491.3062 - val_loss: 2491.3073\n",
      "Epoch 7/20\n",
      " - 6s - loss: 2491.3056 - val_loss: 2491.3072\n",
      "Epoch 8/20\n",
      " - 6s - loss: 2491.3050 - val_loss: 2491.3071\n",
      "Epoch 9/20\n",
      " - 6s - loss: 2491.3049 - val_loss: 2491.3071\n",
      "Epoch 10/20\n",
      " - 6s - loss: 2491.3043 - val_loss: 2491.3070\n",
      "Epoch 11/20\n",
      " - 6s - loss: 2491.3045 - val_loss: 2491.3072\n",
      "Epoch 12/20\n",
      " - 6s - loss: 2491.3044 - val_loss: 2491.3072\n",
      "Epoch 13/20\n",
      " - 6s - loss: 2491.3041 - val_loss: 2491.3071\n",
      "Epoch 14/20\n",
      " - 6s - loss: 2491.3041 - val_loss: 2491.3073\n",
      "Epoch 15/20\n",
      " - 6s - loss: 2491.3043 - val_loss: 2491.3071\n",
      "Epoch 16/20\n",
      " - 6s - loss: 2491.3043 - val_loss: 2491.3071\n",
      "Epoch 17/20\n",
      " - 6s - loss: 2491.3042 - val_loss: 2491.3077\n",
      "Epoch 18/20\n",
      " - 6s - loss: 2491.3041 - val_loss: 2491.3071\n",
      "Epoch 19/20\n",
      " - 6s - loss: 2491.3040 - val_loss: 2491.3070\n",
      "Epoch 20/20\n",
      " - 6s - loss: 2491.3041 - val_loss: 2491.3072\n",
      "Test accuracy: 2491.3071537760416\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 99.3985 - val_loss: 39.9831\n",
      "Epoch 2/20\n",
      " - 11s - loss: 40.0441 - val_loss: 40.0209\n",
      "Epoch 3/20\n",
      " - 11s - loss: 40.0227 - val_loss: 39.9681\n",
      "Epoch 4/20\n",
      " - 11s - loss: 40.0042 - val_loss: 40.0438\n",
      "Epoch 5/20\n",
      " - 11s - loss: 39.9830 - val_loss: 39.9923\n",
      "Epoch 6/20\n",
      " - 11s - loss: 39.9684 - val_loss: 40.0859\n",
      "Epoch 7/20\n",
      " - 11s - loss: 39.9549 - val_loss: 39.8794\n",
      "Epoch 8/20\n",
      " - 11s - loss: 39.9441 - val_loss: 39.8999\n",
      "Epoch 9/20\n",
      " - 11s - loss: 39.9358 - val_loss: 39.8890\n",
      "Epoch 10/20\n",
      " - 11s - loss: 39.9299 - val_loss: 39.9173\n",
      "Epoch 11/20\n",
      " - 11s - loss: 39.9257 - val_loss: 39.9864\n",
      "Epoch 12/20\n",
      " - 11s - loss: 39.9201 - val_loss: 39.9676\n",
      "Epoch 13/20\n",
      " - 11s - loss: 39.9170 - val_loss: 39.9464\n",
      "Epoch 14/20\n",
      " - 11s - loss: 39.9117 - val_loss: 39.9204\n",
      "Epoch 15/20\n",
      " - 11s - loss: 39.9088 - val_loss: 39.9271\n",
      "Epoch 16/20\n",
      " - 11s - loss: 39.9070 - val_loss: 39.9105\n",
      "Epoch 17/20\n",
      " - 11s - loss: 39.9049 - val_loss: 39.9052\n",
      "Epoch 18/20\n",
      " - 11s - loss: 39.9030 - val_loss: 39.8897\n",
      "Epoch 19/20\n",
      " - 11s - loss: 39.9013 - val_loss: 39.8937\n",
      "Epoch 20/20\n",
      " - 11s - loss: 39.9003 - val_loss: 39.8842\n",
      "Test accuracy: 39.884184059651695\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 13s - loss: 3516.5812 - val_loss: 3442.3218\n",
      "Epoch 2/20\n",
      " - 6s - loss: 3442.3222 - val_loss: 3442.3156\n",
      "Epoch 3/20\n",
      " - 6s - loss: 3442.3172 - val_loss: 3442.3132\n",
      "Epoch 4/20\n",
      " - 6s - loss: 3442.3145 - val_loss: 3442.3132\n",
      "Epoch 5/20\n",
      " - 6s - loss: 3442.3129 - val_loss: 3442.3137\n",
      "Epoch 6/20\n",
      " - 6s - loss: 3442.3121 - val_loss: 3442.3134\n",
      "Epoch 7/20\n",
      " - 6s - loss: 3442.3116 - val_loss: 3442.3136\n",
      "Epoch 8/20\n",
      " - 6s - loss: 3442.3111 - val_loss: 3442.3132\n",
      "Epoch 9/20\n",
      " - 6s - loss: 3442.3111 - val_loss: 3442.3138\n",
      "Epoch 10/20\n",
      " - 6s - loss: 3442.3111 - val_loss: 3442.3132\n",
      "Epoch 11/20\n",
      " - 6s - loss: 3442.3107 - val_loss: 3442.3133\n",
      "Epoch 12/20\n",
      " - 6s - loss: 3442.3108 - val_loss: 3442.3135\n",
      "Epoch 13/20\n",
      " - 6s - loss: 3442.3107 - val_loss: 3442.3141\n",
      "Epoch 14/20\n",
      " - 6s - loss: 3442.3107 - val_loss: 3442.3133\n",
      "Epoch 15/20\n",
      " - 6s - loss: 3442.3105 - val_loss: 3442.3136\n",
      "Epoch 16/20\n",
      " - 6s - loss: 3442.3106 - val_loss: 3442.3133\n",
      "Epoch 17/20\n",
      " - 6s - loss: 3442.3108 - val_loss: 3442.3132\n",
      "Epoch 18/20\n",
      " - 6s - loss: 3442.3105 - val_loss: 3442.3133\n",
      "Epoch 19/20\n",
      " - 6s - loss: 3442.3107 - val_loss: 3442.3140\n",
      "Epoch 20/20\n",
      " - 6s - loss: 3442.3106 - val_loss: 3442.3139\n",
      "Test accuracy: 3442.31389609375\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 21s - loss: 330.6035 - val_loss: 78.9138\n",
      "Epoch 2/20\n",
      " - 14s - loss: 79.4101 - val_loss: 79.5633\n",
      "Epoch 3/20\n",
      " - 14s - loss: 79.7033 - val_loss: 79.5610\n",
      "Epoch 4/20\n",
      " - 14s - loss: 79.6865 - val_loss: 79.7545\n",
      "Epoch 5/20\n",
      " - 14s - loss: 79.6461 - val_loss: 78.9087\n",
      "Epoch 6/20\n",
      " - 14s - loss: 79.6243 - val_loss: 79.9326\n",
      "Epoch 7/20\n",
      " - 14s - loss: 79.5932 - val_loss: 79.0369\n",
      "Epoch 8/20\n",
      " - 14s - loss: 79.5812 - val_loss: 79.5607\n",
      "Epoch 9/20\n",
      " - 14s - loss: 79.5926 - val_loss: 79.6912\n",
      "Epoch 10/20\n",
      " - 14s - loss: 79.5778 - val_loss: 79.2900\n",
      "Epoch 11/20\n",
      " - 14s - loss: 79.5893 - val_loss: 79.7933\n",
      "Epoch 12/20\n",
      " - 14s - loss: 79.5988 - val_loss: 79.2287\n",
      "Epoch 13/20\n",
      " - 14s - loss: 79.6061 - val_loss: 79.5915\n",
      "Epoch 14/20\n",
      " - 14s - loss: 79.6153 - val_loss: 79.2907\n",
      "Epoch 15/20\n",
      " - 14s - loss: 79.6292 - val_loss: 79.6620\n",
      "Epoch 16/20\n",
      " - 14s - loss: 79.6602 - val_loss: 79.6420\n",
      "Epoch 17/20\n",
      " - 14s - loss: 79.6767 - val_loss: 79.3617\n",
      "Epoch 18/20\n",
      " - 14s - loss: 79.6979 - val_loss: 79.8181\n",
      "Epoch 19/20\n",
      " - 14s - loss: 79.7152 - val_loss: 79.3668\n",
      "Epoch 20/20\n",
      " - 14s - loss: 79.7334 - val_loss: 79.3706\n",
      "Test accuracy: 79.37058240152994\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 1404.8154 - val_loss: 1374.3466\n",
      "Epoch 2/20\n",
      " - 11s - loss: 1374.4802 - val_loss: 1374.6660\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1374.4765 - val_loss: 1374.4611\n",
      "Epoch 4/20\n",
      " - 11s - loss: 1374.4738 - val_loss: 1374.4768\n",
      "Epoch 5/20\n",
      " - 11s - loss: 1374.4714 - val_loss: 1374.1224\n",
      "Epoch 6/20\n",
      " - 11s - loss: 1374.4696 - val_loss: 1374.1389\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1374.4687 - val_loss: 1374.2324\n",
      "Epoch 8/20\n",
      " - 11s - loss: 1374.4676 - val_loss: 1374.4673\n",
      "Epoch 9/20\n",
      " - 11s - loss: 1374.4662 - val_loss: 1374.6209\n",
      "Epoch 10/20\n",
      " - 11s - loss: 1374.4653 - val_loss: 1374.5324\n",
      "Epoch 11/20\n",
      " - 11s - loss: 1374.4646 - val_loss: 1374.7103\n",
      "Epoch 12/20\n",
      " - 11s - loss: 1374.4636 - val_loss: 1374.3988\n",
      "Epoch 13/20\n",
      " - 11s - loss: 1374.4632 - val_loss: 1374.6092\n",
      "Epoch 14/20\n",
      " - 11s - loss: 1374.4620 - val_loss: 1374.4047\n",
      "Epoch 15/20\n",
      " - 11s - loss: 1374.4616 - val_loss: 1374.4745\n",
      "Epoch 16/20\n",
      " - 11s - loss: 1374.4613 - val_loss: 1374.1714\n",
      "Epoch 17/20\n",
      " - 11s - loss: 1374.4608 - val_loss: 1374.4470\n",
      "Epoch 18/20\n",
      " - 11s - loss: 1374.4601 - val_loss: 1374.4822\n",
      "Epoch 19/20\n",
      " - 11s - loss: 1374.4595 - val_loss: 1374.3702\n",
      "Epoch 20/20\n",
      " - 11s - loss: 1374.4591 - val_loss: 1374.3415\n",
      "Test accuracy: 1374.3414733072916\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 14s - loss: 283.9479 - val_loss: 134.3055\n",
      "Epoch 2/20\n",
      " - 6s - loss: 134.3407 - val_loss: 134.3363\n",
      "Epoch 3/20\n",
      " - 7s - loss: 134.3400 - val_loss: 134.3392\n",
      "Epoch 4/20\n",
      " - 6s - loss: 134.3397 - val_loss: 134.3374\n",
      "Epoch 5/20\n",
      " - 6s - loss: 134.3396 - val_loss: 134.3443\n",
      "Epoch 6/20\n",
      " - 6s - loss: 134.3397 - val_loss: 134.3387\n",
      "Epoch 7/20\n",
      " - 6s - loss: 134.3398 - val_loss: 134.3389\n",
      "Epoch 8/20\n",
      " - 6s - loss: 134.3391 - val_loss: 134.3368\n",
      "Epoch 9/20\n",
      " - 6s - loss: 134.3388 - val_loss: 134.3383\n",
      "Epoch 10/20\n",
      " - 6s - loss: 134.3389 - val_loss: 134.3374\n",
      "Epoch 11/20\n",
      " - 6s - loss: 134.3384 - val_loss: 134.3375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      " - 6s - loss: 134.3386 - val_loss: 134.3503\n",
      "Epoch 13/20\n",
      " - 6s - loss: 134.3385 - val_loss: 134.3372\n",
      "Epoch 14/20\n",
      " - 6s - loss: 134.3382 - val_loss: 134.3376\n",
      "Epoch 15/20\n",
      " - 6s - loss: 134.3385 - val_loss: 134.3371\n",
      "Epoch 16/20\n",
      " - 6s - loss: 134.3378 - val_loss: 134.3379\n",
      "Epoch 17/20\n",
      " - 6s - loss: 134.3379 - val_loss: 134.3371\n",
      "Epoch 18/20\n",
      " - 6s - loss: 134.3379 - val_loss: 134.3378\n",
      "Epoch 19/20\n",
      " - 6s - loss: 134.3374 - val_loss: 134.3411\n",
      "Epoch 20/20\n",
      " - 6s - loss: 134.3382 - val_loss: 134.3394\n",
      "Test accuracy: 134.33937866210937\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 194.9768 - val_loss: 44.7140\n",
      "Epoch 2/20\n",
      " - 12s - loss: 44.4709 - val_loss: 44.4004\n",
      "Epoch 3/20\n",
      " - 13s - loss: 44.2933 - val_loss: 44.3066\n",
      "Epoch 4/20\n",
      " - 13s - loss: 44.2204 - val_loss: 44.1571\n",
      "Epoch 5/20\n",
      " - 12s - loss: 44.1522 - val_loss: 44.0289\n",
      "Epoch 6/20\n",
      " - 12s - loss: 44.1345 - val_loss: 44.2133\n",
      "Epoch 7/20\n",
      " - 13s - loss: 44.1000 - val_loss: 44.0344\n",
      "Epoch 8/20\n",
      " - 13s - loss: 44.0402 - val_loss: 43.9510\n",
      "Epoch 9/20\n",
      " - 12s - loss: 43.9502 - val_loss: 44.0025\n",
      "Epoch 10/20\n",
      " - 12s - loss: 43.9076 - val_loss: 43.8822\n",
      "Epoch 11/20\n",
      " - 13s - loss: 43.8360 - val_loss: 43.8253\n",
      "Epoch 12/20\n",
      " - 13s - loss: 43.7909 - val_loss: 43.8251\n",
      "Epoch 13/20\n",
      " - 12s - loss: 43.7526 - val_loss: 43.7400\n",
      "Epoch 14/20\n",
      " - 12s - loss: 43.7024 - val_loss: 43.6468\n",
      "Epoch 15/20\n",
      " - 12s - loss: 43.6479 - val_loss: 43.6558\n",
      "Epoch 16/20\n",
      " - 13s - loss: 43.6187 - val_loss: 43.6124\n",
      "Epoch 17/20\n",
      " - 13s - loss: 43.5527 - val_loss: 43.5240\n",
      "Epoch 18/20\n",
      " - 12s - loss: 43.5276 - val_loss: 43.5593\n",
      "Epoch 19/20\n",
      " - 13s - loss: 43.5135 - val_loss: 43.4786\n",
      "Epoch 20/20\n",
      " - 13s - loss: 43.4887 - val_loss: 43.4100\n",
      "Test accuracy: 43.40996370849609\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 1109.7822 - val_loss: 1074.8243\n",
      "Epoch 2/20\n",
      " - 12s - loss: 1074.8231 - val_loss: 1074.8267\n",
      "Epoch 3/20\n",
      " - 12s - loss: 1074.8230 - val_loss: 1074.8252\n",
      "Epoch 4/20\n",
      " - 12s - loss: 1074.8228 - val_loss: 1074.8253\n",
      "Epoch 5/20\n",
      " - 12s - loss: 1074.8225 - val_loss: 1074.8243\n",
      "Epoch 6/20\n",
      " - 12s - loss: 1074.8226 - val_loss: 1074.8250\n",
      "Epoch 7/20\n",
      " - 12s - loss: 1074.8223 - val_loss: 1074.8243\n",
      "Epoch 8/20\n",
      " - 12s - loss: 1074.8223 - val_loss: 1074.8243\n",
      "Epoch 9/20\n",
      " - 12s - loss: 1074.8221 - val_loss: 1074.8256\n",
      "Epoch 10/20\n",
      " - 12s - loss: 1074.8221 - val_loss: 1074.8244\n",
      "Epoch 11/20\n",
      " - 12s - loss: 1074.8220 - val_loss: 1074.8252\n",
      "Epoch 12/20\n",
      " - 12s - loss: 1074.8219 - val_loss: 1074.8258\n",
      "Epoch 13/20\n",
      " - 12s - loss: 1074.8217 - val_loss: 1074.8258\n",
      "Epoch 14/20\n",
      " - 12s - loss: 1074.8216 - val_loss: 1074.8247\n",
      "Epoch 15/20\n",
      " - 12s - loss: 1074.8217 - val_loss: 1074.8247\n",
      "Epoch 16/20\n",
      " - 12s - loss: 1074.8215 - val_loss: 1074.8245\n",
      "Epoch 17/20\n",
      " - 12s - loss: 1074.8215 - val_loss: 1074.8244\n",
      "Epoch 18/20\n",
      " - 12s - loss: 1074.8214 - val_loss: 1074.8245\n",
      "Epoch 19/20\n",
      " - 12s - loss: 1074.8213 - val_loss: 1074.8272\n",
      "Epoch 20/20\n",
      " - 12s - loss: 1074.8215 - val_loss: 1074.8243\n",
      "Test accuracy: 1074.8243401041666\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 788.1392 - val_loss: 139.6450\n",
      "Epoch 2/20\n",
      " - 8s - loss: 137.4843 - val_loss: 137.3221\n",
      "Epoch 3/20\n",
      " - 8s - loss: 136.5146 - val_loss: 136.7384\n",
      "Epoch 4/20\n",
      " - 8s - loss: 135.7578 - val_loss: 135.7483\n",
      "Epoch 5/20\n",
      " - 8s - loss: 136.7078 - val_loss: 136.9747\n",
      "Epoch 6/20\n",
      " - 8s - loss: 136.9799 - val_loss: 137.0331\n",
      "Epoch 7/20\n",
      " - 8s - loss: 137.3269 - val_loss: 137.9452\n",
      "Epoch 8/20\n",
      " - 8s - loss: 138.5633 - val_loss: 139.3583\n",
      "Epoch 9/20\n",
      " - 8s - loss: 140.3055 - val_loss: 141.7629\n",
      "Epoch 10/20\n",
      " - 8s - loss: 140.7253 - val_loss: 138.9342\n",
      "Epoch 11/20\n",
      " - 8s - loss: 140.7435 - val_loss: 141.5378\n",
      "Epoch 12/20\n",
      " - 8s - loss: 140.7730 - val_loss: 141.0973\n",
      "Epoch 13/20\n",
      " - 8s - loss: 140.8230 - val_loss: 140.4145\n",
      "Epoch 14/20\n",
      " - 8s - loss: 140.8665 - val_loss: 139.4280\n",
      "Epoch 15/20\n",
      " - 8s - loss: 140.8670 - val_loss: 142.4378\n",
      "Epoch 16/20\n",
      " - 8s - loss: 140.8661 - val_loss: 140.4983\n",
      "Epoch 17/20\n",
      " - 8s - loss: 140.8599 - val_loss: 140.5589\n",
      "Epoch 18/20\n",
      " - 8s - loss: 140.8601 - val_loss: 140.8496\n",
      "Epoch 19/20\n",
      " - 8s - loss: 140.8579 - val_loss: 141.1947\n",
      "Epoch 20/20\n",
      " - 8s - loss: 140.8560 - val_loss: 140.3111\n",
      "Test accuracy: 140.31112057291668\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 23s - loss: 958.4221 - val_loss: 695.1269\n",
      "Epoch 2/20\n",
      " - 15s - loss: 695.5942 - val_loss: 695.0003\n",
      "Epoch 3/20\n",
      " - 15s - loss: 695.5964 - val_loss: 694.8985\n",
      "Epoch 4/20\n",
      " - 15s - loss: 695.5977 - val_loss: 695.2548\n",
      "Epoch 5/20\n",
      " - 15s - loss: 695.5982 - val_loss: 695.4543\n",
      "Epoch 6/20\n",
      " - 15s - loss: 695.6000 - val_loss: 695.3880\n",
      "Epoch 7/20\n",
      " - 15s - loss: 695.6010 - val_loss: 695.2411\n",
      "Epoch 8/20\n",
      " - 15s - loss: 695.6021 - val_loss: 694.9739\n",
      "Epoch 9/20\n",
      " - 15s - loss: 695.6023 - val_loss: 695.0526\n",
      "Epoch 10/20\n",
      " - 15s - loss: 695.6026 - val_loss: 694.8340\n",
      "Epoch 11/20\n",
      " - 15s - loss: 695.6037 - val_loss: 694.8078\n",
      "Epoch 12/20\n",
      " - 15s - loss: 695.6039 - val_loss: 694.7251\n",
      "Epoch 13/20\n",
      " - 15s - loss: 695.6053 - val_loss: 696.2369\n",
      "Epoch 14/20\n",
      " - 15s - loss: 695.6057 - val_loss: 695.0629\n",
      "Epoch 15/20\n",
      " - 15s - loss: 695.6064 - val_loss: 695.7069\n",
      "Epoch 16/20\n",
      " - 15s - loss: 695.6078 - val_loss: 695.2420\n",
      "Epoch 17/20\n",
      " - 15s - loss: 695.6078 - val_loss: 695.4014\n",
      "Epoch 18/20\n",
      " - 15s - loss: 695.6096 - val_loss: 695.4055\n",
      "Epoch 19/20\n",
      " - 15s - loss: 695.6103 - val_loss: 695.3365\n",
      "Epoch 20/20\n",
      " - 15s - loss: 695.6121 - val_loss: 695.7385\n",
      "Test accuracy: 695.7384751627604\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 1025.6754 - val_loss: 1004.5959\n",
      "Epoch 2/20\n",
      " - 11s - loss: 1005.7122 - val_loss: 1005.6737\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1005.7087 - val_loss: 1005.7115\n",
      "Epoch 4/20\n",
      " - 11s - loss: 1005.7070 - val_loss: 1005.7030\n",
      "Epoch 5/20\n",
      " - 11s - loss: 1005.7068 - val_loss: 1005.7119\n",
      "Epoch 6/20\n",
      " - 11s - loss: 1005.7064 - val_loss: 1005.7092\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1005.7064 - val_loss: 1005.7084\n",
      "Epoch 8/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7090\n",
      "Epoch 9/20\n",
      " - 11s - loss: 1005.7063 - val_loss: 1005.7094\n",
      "Epoch 10/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7093\n",
      "Epoch 11/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7078\n",
      "Epoch 12/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7100\n",
      "Epoch 13/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7083\n",
      "Epoch 14/20\n",
      " - 11s - loss: 1005.7061 - val_loss: 1005.7092\n",
      "Epoch 15/20\n",
      " - 11s - loss: 1005.7061 - val_loss: 1005.7087\n",
      "Epoch 16/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7094\n",
      "Epoch 17/20\n",
      " - 11s - loss: 1005.7061 - val_loss: 1005.7089\n",
      "Epoch 18/20\n",
      " - 11s - loss: 1005.7061 - val_loss: 1005.7094\n",
      "Epoch 19/20\n",
      " - 11s - loss: 1005.7061 - val_loss: 1005.7094\n",
      "Epoch 20/20\n",
      " - 11s - loss: 1005.7062 - val_loss: 1005.7089\n",
      "Test accuracy: 1005.7088559895833\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 1559.6078 - val_loss: 1531.0466\n",
      "Epoch 2/20\n",
      " - 11s - loss: 1531.0405 - val_loss: 1531.0393\n",
      "Epoch 3/20\n",
      " - 11s - loss: 1531.0398 - val_loss: 1531.0440\n",
      "Epoch 4/20\n",
      " - 11s - loss: 1531.0400 - val_loss: 1531.0389\n",
      "Epoch 5/20\n",
      " - 11s - loss: 1531.0397 - val_loss: 1531.0413\n",
      "Epoch 6/20\n",
      " - 11s - loss: 1531.0401 - val_loss: 1531.0425\n",
      "Epoch 7/20\n",
      " - 11s - loss: 1531.0397 - val_loss: 1531.0409\n",
      "Epoch 8/20\n",
      " - 11s - loss: 1531.0399 - val_loss: 1531.0394\n",
      "Epoch 9/20\n",
      " - 11s - loss: 1531.0400 - val_loss: 1531.0449\n",
      "Epoch 10/20\n",
      " - 11s - loss: 1531.0398 - val_loss: 1531.0381\n",
      "Epoch 11/20\n",
      " - 11s - loss: 1531.0391 - val_loss: 1531.0403\n",
      "Epoch 12/20\n",
      " - 11s - loss: 1531.0398 - val_loss: 1531.0430\n",
      "Epoch 13/20\n",
      " - 11s - loss: 1531.0396 - val_loss: 1531.0439\n",
      "Epoch 14/20\n",
      " - 11s - loss: 1531.0394 - val_loss: 1531.0394\n",
      "Epoch 15/20\n",
      " - 11s - loss: 1531.0396 - val_loss: 1531.0414\n",
      "Epoch 16/20\n",
      " - 11s - loss: 1531.0394 - val_loss: 1531.0360\n",
      "Epoch 17/20\n",
      " - 11s - loss: 1531.0395 - val_loss: 1531.0370\n",
      "Epoch 18/20\n",
      " - 11s - loss: 1531.0392 - val_loss: 1531.0400\n",
      "Epoch 19/20\n",
      " - 11s - loss: 1531.0394 - val_loss: 1531.0387\n",
      "Epoch 20/20\n",
      " - 11s - loss: 1531.0394 - val_loss: 1531.0403\n",
      "Test accuracy: 1531.0403143229166\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 812.8586 - val_loss: 140.0264\n",
      "Epoch 2/20\n",
      " - 10s - loss: 139.6086 - val_loss: 140.0895\n",
      "Epoch 3/20\n",
      " - 10s - loss: 139.9155 - val_loss: 140.9496\n",
      "Epoch 4/20\n",
      " - 10s - loss: 140.7247 - val_loss: 140.5436\n",
      "Epoch 5/20\n",
      " - 10s - loss: 140.6589 - val_loss: 140.6215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      " - 11s - loss: 140.5429 - val_loss: 140.4173\n",
      "Epoch 7/20\n",
      " - 11s - loss: 140.4197 - val_loss: 140.2635\n",
      "Epoch 8/20\n",
      " - 11s - loss: 140.2982 - val_loss: 140.3648\n",
      "Epoch 9/20\n",
      " - 10s - loss: 140.2287 - val_loss: 141.1914\n",
      "Epoch 10/20\n",
      " - 10s - loss: 140.1841 - val_loss: 139.3175\n",
      "Epoch 11/20\n",
      " - 11s - loss: 140.1798 - val_loss: 140.1278\n",
      "Epoch 12/20\n",
      " - 11s - loss: 140.2201 - val_loss: 140.6326\n",
      "Epoch 13/20\n",
      " - 11s - loss: 140.3201 - val_loss: 140.3508\n",
      "Epoch 14/20\n",
      " - 11s - loss: 140.4518 - val_loss: 140.3439\n",
      "Epoch 15/20\n",
      " - 11s - loss: 140.5812 - val_loss: 141.3944\n",
      "Epoch 16/20\n",
      " - 11s - loss: 140.7204 - val_loss: 140.1574\n",
      "Epoch 17/20\n",
      " - 11s - loss: 140.8590 - val_loss: 140.7331\n",
      "Epoch 18/20\n",
      " - 11s - loss: 140.9787 - val_loss: 141.8246\n",
      "Epoch 19/20\n",
      " - 11s - loss: 141.0934 - val_loss: 141.4842\n",
      "Epoch 20/20\n",
      " - 11s - loss: 141.1952 - val_loss: 140.8690\n",
      "Test accuracy: 140.8690276936849\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 22s - loss: 1686.6846 - val_loss: 1655.9246\n",
      "Epoch 2/20\n",
      " - 12s - loss: 1655.9256 - val_loss: 1655.9261\n",
      "Epoch 3/20\n",
      " - 12s - loss: 1655.9245 - val_loss: 1655.9270\n",
      "Epoch 4/20\n",
      " - 12s - loss: 1655.9239 - val_loss: 1655.9247\n",
      "Epoch 5/20\n",
      " - 12s - loss: 1655.9235 - val_loss: 1655.9256\n",
      "Epoch 6/20\n",
      " - 12s - loss: 1655.9233 - val_loss: 1655.9253\n",
      "Epoch 7/20\n",
      " - 12s - loss: 1655.9230 - val_loss: 1655.9259\n",
      "Epoch 8/20\n",
      " - 12s - loss: 1655.9229 - val_loss: 1655.9253\n",
      "Epoch 9/20\n",
      " - 12s - loss: 1655.9227 - val_loss: 1655.9238\n",
      "Epoch 10/20\n",
      " - 12s - loss: 1655.9225 - val_loss: 1655.9248\n",
      "Epoch 11/20\n",
      " - 12s - loss: 1655.9223 - val_loss: 1655.9250\n",
      "Epoch 12/20\n",
      " - 12s - loss: 1655.9224 - val_loss: 1655.9223\n",
      "Epoch 13/20\n",
      " - 12s - loss: 1655.9224 - val_loss: 1655.9264\n",
      "Epoch 14/20\n",
      " - 12s - loss: 1655.9221 - val_loss: 1655.9270\n",
      "Epoch 15/20\n",
      " - 12s - loss: 1655.9220 - val_loss: 1655.9245\n",
      "Epoch 16/20\n",
      " - 12s - loss: 1655.9222 - val_loss: 1655.9252\n",
      "Epoch 17/20\n",
      " - 12s - loss: 1655.9219 - val_loss: 1655.9241\n",
      "Epoch 18/20\n",
      " - 12s - loss: 1655.9220 - val_loss: 1655.9227\n",
      "Epoch 19/20\n",
      " - 12s - loss: 1655.9219 - val_loss: 1655.9248\n",
      "Epoch 20/20\n",
      " - 12s - loss: 1655.9218 - val_loss: 1655.9283\n",
      "Test accuracy: 1655.9283314453126\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 24s - loss: 930.4663 - val_loss: 682.3798\n",
      "Epoch 2/20\n",
      " - 15s - loss: 681.9302 - val_loss: 682.1391\n",
      "Epoch 3/20\n",
      " - 15s - loss: 681.9361 - val_loss: 682.1521\n",
      "Epoch 4/20\n",
      " - 15s - loss: 681.9418 - val_loss: 682.0432\n",
      "Epoch 5/20\n",
      " - 15s - loss: 681.9498 - val_loss: 682.3170\n",
      "Epoch 6/20\n",
      " - 15s - loss: 681.9624 - val_loss: 682.0857\n",
      "Epoch 7/20\n",
      " - 15s - loss: 681.9775 - val_loss: 682.0721\n",
      "Epoch 8/20\n",
      " - 15s - loss: 681.9957 - val_loss: 682.8320\n",
      "Epoch 9/20\n",
      " - 15s - loss: 682.0192 - val_loss: 682.9671\n",
      "Epoch 10/20\n",
      " - 15s - loss: 682.0447 - val_loss: 682.7195\n",
      "Epoch 11/20\n",
      " - 15s - loss: 682.0737 - val_loss: 682.6378\n",
      "Epoch 12/20\n",
      " - 15s - loss: 682.1038 - val_loss: 684.4204\n",
      "Epoch 13/20\n",
      " - 15s - loss: 682.1381 - val_loss: 683.5729\n",
      "Epoch 14/20\n",
      " - 15s - loss: 682.1654 - val_loss: 681.5148\n",
      "Epoch 15/20\n",
      " - 15s - loss: 682.1931 - val_loss: 684.2321\n",
      "Epoch 16/20\n",
      " - 15s - loss: 682.2233 - val_loss: 683.3146\n",
      "Epoch 17/20\n",
      " - 15s - loss: 682.2522 - val_loss: 682.0729\n",
      "Epoch 18/20\n",
      " - 16s - loss: 682.2799 - val_loss: 684.2855\n",
      "Epoch 19/20\n",
      " - 16s - loss: 682.2998 - val_loss: 682.8639\n",
      "Epoch 20/20\n",
      " - 16s - loss: 682.3223 - val_loss: 684.3258\n",
      "Test accuracy: 684.3258380533854\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 22s - loss: 1517.7629 - val_loss: 1492.4185\n",
      "Epoch 2/20\n",
      " - 13s - loss: 1492.4139 - val_loss: 1492.4119\n",
      "Epoch 3/20\n",
      " - 13s - loss: 1492.4113 - val_loss: 1492.4092\n",
      "Epoch 4/20\n",
      " - 13s - loss: 1492.4113 - val_loss: 1492.4093\n",
      "Epoch 5/20\n",
      " - 13s - loss: 1492.4112 - val_loss: 1492.4119\n",
      "Epoch 6/20\n",
      " - 13s - loss: 1492.4110 - val_loss: 1492.4131\n",
      "Epoch 7/20\n",
      " - 13s - loss: 1492.4115 - val_loss: 1492.4137\n",
      "Epoch 8/20\n",
      " - 12s - loss: 1492.4109 - val_loss: 1492.4132\n",
      "Epoch 9/20\n",
      " - 12s - loss: 1492.4113 - val_loss: 1492.4138\n",
      "Epoch 10/20\n",
      " - 12s - loss: 1492.4107 - val_loss: 1492.4119\n",
      "Epoch 11/20\n",
      " - 12s - loss: 1492.4109 - val_loss: 1492.4116\n",
      "Epoch 12/20\n",
      " - 12s - loss: 1492.4113 - val_loss: 1492.4138\n",
      "Epoch 13/20\n",
      " - 12s - loss: 1492.4109 - val_loss: 1492.4133\n",
      "Epoch 14/20\n",
      " - 12s - loss: 1492.4107 - val_loss: 1492.4145\n",
      "Epoch 15/20\n",
      " - 12s - loss: 1492.4113 - val_loss: 1492.4098\n",
      "Epoch 16/20\n",
      " - 12s - loss: 1492.4110 - val_loss: 1492.4177\n",
      "Epoch 17/20\n",
      " - 12s - loss: 1492.4112 - val_loss: 1492.4142\n",
      "Epoch 18/20\n",
      " - 12s - loss: 1492.4109 - val_loss: 1492.4114\n",
      "Epoch 19/20\n",
      " - 12s - loss: 1492.4109 - val_loss: 1492.4152\n",
      "Epoch 20/20\n",
      " - 12s - loss: 1492.4111 - val_loss: 1492.4115\n",
      "Test accuracy: 1492.411469140625\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 728.8916 - val_loss: 114.1630\n",
      "Epoch 2/20\n",
      " - 9s - loss: 114.6429 - val_loss: 114.8746\n",
      "Epoch 3/20\n",
      " - 9s - loss: 114.6532 - val_loss: 114.9462\n",
      "Epoch 4/20\n",
      " - 9s - loss: 114.4693 - val_loss: 114.1295\n",
      "Epoch 5/20\n",
      " - 9s - loss: 114.3912 - val_loss: 114.2347\n",
      "Epoch 6/20\n",
      " - 9s - loss: 114.3495 - val_loss: 114.3702\n",
      "Epoch 7/20\n",
      " - 9s - loss: 114.4130 - val_loss: 114.7856\n",
      "Epoch 8/20\n",
      " - 9s - loss: 114.5369 - val_loss: 114.9448\n",
      "Epoch 9/20\n",
      " - 9s - loss: 114.7542 - val_loss: 115.5563\n",
      "Epoch 10/20\n",
      " - 9s - loss: 114.8689 - val_loss: 114.0267\n",
      "Epoch 11/20\n",
      " - 9s - loss: 115.0369 - val_loss: 115.2034\n",
      "Epoch 12/20\n",
      " - 9s - loss: 115.1935 - val_loss: 115.6782\n",
      "Epoch 13/20\n",
      " - 9s - loss: 115.3400 - val_loss: 115.6514\n",
      "Epoch 14/20\n",
      " - 9s - loss: 115.5064 - val_loss: 115.2233\n",
      "Epoch 15/20\n",
      " - 9s - loss: 115.6337 - val_loss: 116.1822\n",
      "Epoch 16/20\n",
      " - 9s - loss: 115.7600 - val_loss: 115.3521\n",
      "Epoch 17/20\n",
      " - 9s - loss: 115.8561 - val_loss: 115.9189\n",
      "Epoch 18/20\n",
      " - 9s - loss: 115.9350 - val_loss: 116.5435\n",
      "Epoch 19/20\n",
      " - 9s - loss: 115.9660 - val_loss: 116.3631\n",
      "Epoch 20/20\n",
      " - 9s - loss: 116.0267 - val_loss: 115.6033\n",
      "Test accuracy: 115.60333207600911\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 300.6540 - val_loss: 278.6515\n",
      "Epoch 2/20\n",
      " - 11s - loss: 278.6488 - val_loss: 278.6515\n",
      "Epoch 3/20\n",
      " - 11s - loss: 278.6486 - val_loss: 278.6515\n",
      "Epoch 4/20\n",
      " - 11s - loss: 278.6486 - val_loss: 278.6515\n",
      "Epoch 5/20\n",
      " - 11s - loss: 278.6484 - val_loss: 278.6516\n",
      "Epoch 6/20\n",
      " - 11s - loss: 278.6485 - val_loss: 278.6515\n",
      "Epoch 7/20\n",
      " - 11s - loss: 278.6485 - val_loss: 278.6515\n",
      "Epoch 8/20\n",
      " - 11s - loss: 278.6484 - val_loss: 278.6516\n",
      "Epoch 9/20\n",
      " - 11s - loss: 278.6486 - val_loss: 278.6515\n",
      "Epoch 10/20\n",
      " - 11s - loss: 278.6482 - val_loss: 278.6515\n",
      "Epoch 11/20\n",
      " - 11s - loss: 278.6483 - val_loss: 278.6515\n",
      "Epoch 12/20\n",
      " - 11s - loss: 278.6484 - val_loss: 278.6515\n",
      "Epoch 13/20\n",
      " - 11s - loss: 278.6481 - val_loss: 278.6515\n",
      "Epoch 14/20\n",
      " - 11s - loss: 278.6483 - val_loss: 278.6515\n",
      "Epoch 15/20\n",
      " - 11s - loss: 278.6484 - val_loss: 278.6517\n",
      "Epoch 16/20\n",
      " - 11s - loss: 278.6484 - val_loss: 278.6516\n",
      "Epoch 17/20\n",
      " - 11s - loss: 278.6483 - val_loss: 278.6516\n",
      "Epoch 18/20\n",
      " - 11s - loss: 278.6483 - val_loss: 278.6515\n",
      "Epoch 19/20\n",
      " - 11s - loss: 278.6482 - val_loss: 278.6516\n",
      "Epoch 20/20\n",
      " - 11s - loss: 278.6482 - val_loss: 278.6516\n",
      "Test accuracy: 278.6515828450521\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 24s - loss: 3401.1315 - val_loss: 3357.0788\n",
      "Epoch 2/20\n",
      " - 13s - loss: 3357.2252 - val_loss: 3357.1447\n",
      "Epoch 3/20\n",
      " - 13s - loss: 3357.2231 - val_loss: 3357.2040\n",
      "Epoch 4/20\n",
      " - 13s - loss: 3357.2224 - val_loss: 3357.2239\n",
      "Epoch 5/20\n",
      " - 13s - loss: 3357.2211 - val_loss: 3357.1922\n",
      "Epoch 6/20\n",
      " - 13s - loss: 3357.2209 - val_loss: 3357.3963\n",
      "Epoch 7/20\n",
      " - 13s - loss: 3357.2207 - val_loss: 3357.0943\n",
      "Epoch 8/20\n",
      " - 13s - loss: 3357.2205 - val_loss: 3357.1059\n",
      "Epoch 9/20\n",
      " - 13s - loss: 3357.2203 - val_loss: 3357.3289\n",
      "Epoch 10/20\n",
      " - 13s - loss: 3357.2205 - val_loss: 3357.3377\n",
      "Epoch 11/20\n",
      " - 13s - loss: 3357.2197 - val_loss: 3357.1932\n",
      "Epoch 12/20\n",
      " - 13s - loss: 3357.2196 - val_loss: 3357.2332\n",
      "Epoch 13/20\n",
      " - 13s - loss: 3357.2199 - val_loss: 3357.4091\n",
      "Epoch 14/20\n",
      " - 14s - loss: 3357.2193 - val_loss: 3357.4656\n",
      "Epoch 15/20\n",
      " - 14s - loss: 3357.2191 - val_loss: 3357.1138\n",
      "Epoch 16/20\n",
      " - 14s - loss: 3357.2186 - val_loss: 3357.1668\n",
      "Epoch 17/20\n",
      " - 14s - loss: 3357.2186 - val_loss: 3357.3712\n",
      "Epoch 18/20\n",
      " - 14s - loss: 3357.2186 - val_loss: 3357.5366\n",
      "Epoch 19/20\n",
      " - 14s - loss: 3357.2184 - val_loss: 3357.0816\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 14s - loss: 3357.2179 - val_loss: 3357.2775\n",
      "Test accuracy: 3357.2774674479165\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 24s - loss: 446.9225 - val_loss: 288.7557\n",
      "Epoch 2/20\n",
      " - 14s - loss: 288.7720 - val_loss: 288.7722\n",
      "Epoch 3/20\n",
      " - 14s - loss: 288.7718 - val_loss: 288.7726\n",
      "Epoch 4/20\n",
      " - 13s - loss: 288.7716 - val_loss: 288.7751\n",
      "Epoch 5/20\n",
      " - 14s - loss: 288.7714 - val_loss: 288.7672\n",
      "Epoch 6/20\n",
      " - 13s - loss: 288.7710 - val_loss: 288.7680\n",
      "Epoch 7/20\n",
      " - 13s - loss: 288.7701 - val_loss: 288.7717\n",
      "Epoch 8/20\n",
      " - 13s - loss: 288.7702 - val_loss: 288.7663\n",
      "Epoch 9/20\n",
      " - 13s - loss: 288.7699 - val_loss: 288.7684\n",
      "Epoch 10/20\n",
      " - 13s - loss: 288.7698 - val_loss: 288.7646\n",
      "Epoch 11/20\n",
      " - 13s - loss: 288.7697 - val_loss: 288.7710\n",
      "Epoch 12/20\n",
      " - 13s - loss: 288.7693 - val_loss: 288.7689\n",
      "Epoch 13/20\n",
      " - 13s - loss: 288.7693 - val_loss: 288.7754\n",
      "Epoch 14/20\n",
      " - 13s - loss: 288.7690 - val_loss: 288.7677\n",
      "Epoch 15/20\n",
      " - 13s - loss: 288.7693 - val_loss: 288.7714\n",
      "Epoch 16/20\n",
      " - 13s - loss: 288.7688 - val_loss: 288.7711\n",
      "Epoch 17/20\n",
      " - 13s - loss: 288.7686 - val_loss: 288.7671\n",
      "Epoch 18/20\n",
      " - 13s - loss: 288.7688 - val_loss: 288.7713\n",
      "Epoch 19/20\n",
      " - 13s - loss: 288.7689 - val_loss: 288.7725\n",
      "Epoch 20/20\n",
      " - 13s - loss: 288.7684 - val_loss: 288.7720\n",
      "Test accuracy: 288.77201331380206\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 24s - loss: 4996.3296 - val_loss: 4952.0606\n",
      "Epoch 2/20\n",
      " - 14s - loss: 4952.0380 - val_loss: 4951.9977\n",
      "Epoch 3/20\n",
      " - 14s - loss: 4952.0195 - val_loss: 4952.0137\n",
      "Epoch 4/20\n",
      " - 14s - loss: 4952.0125 - val_loss: 4951.8790\n",
      "Epoch 5/20\n",
      " - 14s - loss: 4952.0090 - val_loss: 4951.9857\n",
      "Epoch 6/20\n",
      " - 14s - loss: 4952.0074 - val_loss: 4952.0520\n",
      "Epoch 7/20\n",
      " - 14s - loss: 4952.0065 - val_loss: 4952.1046\n",
      "Epoch 8/20\n",
      " - 14s - loss: 4952.0064 - val_loss: 4952.0174\n",
      "Epoch 9/20\n",
      " - 14s - loss: 4952.0057 - val_loss: 4952.0581\n",
      "Epoch 10/20\n",
      " - 14s - loss: 4952.0057 - val_loss: 4952.0526\n",
      "Epoch 11/20\n",
      " - 14s - loss: 4952.0054 - val_loss: 4952.1002\n",
      "Epoch 12/20\n",
      " - 14s - loss: 4952.0054 - val_loss: 4951.9937\n",
      "Epoch 13/20\n",
      " - 14s - loss: 4952.0055 - val_loss: 4952.0111\n",
      "Epoch 14/20\n",
      " - 14s - loss: 4952.0054 - val_loss: 4951.9594\n",
      "Epoch 15/20\n",
      " - 13s - loss: 4952.0052 - val_loss: 4952.0147\n",
      "Epoch 16/20\n",
      " - 13s - loss: 4952.0051 - val_loss: 4952.0242\n",
      "Epoch 17/20\n",
      " - 13s - loss: 4952.0054 - val_loss: 4951.9721\n",
      "Epoch 18/20\n",
      " - 13s - loss: 4952.0051 - val_loss: 4952.1066\n",
      "Epoch 19/20\n",
      " - 13s - loss: 4952.0053 - val_loss: 4952.0014\n",
      "Epoch 20/20\n",
      " - 13s - loss: 4952.0050 - val_loss: 4951.9557\n",
      "Test accuracy: 4951.955674479167\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 170.4693 - val_loss: 21.6605\n",
      "Epoch 2/20\n",
      " - 7s - loss: 21.8709 - val_loss: 21.9998\n",
      "Epoch 3/20\n",
      " - 7s - loss: 21.9848 - val_loss: 22.0463\n",
      "Epoch 4/20\n",
      " - 7s - loss: 22.0022 - val_loss: 21.9173\n",
      "Epoch 5/20\n",
      " - 7s - loss: 22.0006 - val_loss: 22.0250\n",
      "Epoch 6/20\n",
      " - 7s - loss: 21.9972 - val_loss: 21.9856\n",
      "Epoch 7/20\n",
      " - 7s - loss: 21.9958 - val_loss: 22.0607\n",
      "Epoch 8/20\n",
      " - 7s - loss: 21.9918 - val_loss: 22.0683\n",
      "Epoch 9/20\n",
      " - 7s - loss: 21.9972 - val_loss: 22.0542\n",
      "Epoch 10/20\n",
      " - 7s - loss: 21.9956 - val_loss: 21.8390\n",
      "Epoch 11/20\n",
      " - 7s - loss: 21.9915 - val_loss: 22.0682\n",
      "Epoch 12/20\n",
      " - 7s - loss: 21.9897 - val_loss: 22.0832\n",
      "Epoch 13/20\n",
      " - 7s - loss: 21.9894 - val_loss: 21.9988\n",
      "Epoch 14/20\n",
      " - 7s - loss: 21.9882 - val_loss: 21.9202\n",
      "Epoch 15/20\n",
      " - 7s - loss: 21.9914 - val_loss: 22.0284\n",
      "Epoch 16/20\n",
      " - 7s - loss: 21.9872 - val_loss: 21.9255\n",
      "Epoch 17/20\n",
      " - 7s - loss: 21.9893 - val_loss: 22.0314\n",
      "Epoch 18/20\n",
      " - 7s - loss: 21.9906 - val_loss: 22.0817\n",
      "Epoch 19/20\n",
      " - 7s - loss: 21.9873 - val_loss: 22.0187\n",
      "Epoch 20/20\n",
      " - 7s - loss: 21.9845 - val_loss: 21.9166\n",
      "Test accuracy: 21.91657796122233\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 24s - loss: 6043.1973 - val_loss: 5999.8505\n",
      "Epoch 2/20\n",
      " - 14s - loss: 5999.6212 - val_loss: 5999.2400\n",
      "Epoch 3/20\n",
      " - 14s - loss: 5999.6161 - val_loss: 5999.2500\n",
      "Epoch 4/20\n",
      " - 14s - loss: 5999.6118 - val_loss: 5999.7198\n",
      "Epoch 5/20\n",
      " - 14s - loss: 5999.6087 - val_loss: 5999.8007\n",
      "Epoch 6/20\n",
      " - 14s - loss: 5999.6067 - val_loss: 5999.5858\n",
      "Epoch 7/20\n",
      " - 14s - loss: 5999.6040 - val_loss: 5999.3096\n",
      "Epoch 8/20\n",
      " - 14s - loss: 5999.6018 - val_loss: 5999.5669\n",
      "Epoch 9/20\n",
      " - 14s - loss: 5999.6008 - val_loss: 5999.7818\n",
      "Epoch 10/20\n",
      " - 14s - loss: 5999.5999 - val_loss: 5999.2568\n",
      "Epoch 11/20\n",
      " - 14s - loss: 5999.5985 - val_loss: 5999.4814\n",
      "Epoch 12/20\n",
      " - 14s - loss: 5999.5974 - val_loss: 5999.8268\n",
      "Epoch 13/20\n",
      " - 14s - loss: 5999.5971 - val_loss: 5999.4436\n",
      "Epoch 14/20\n",
      " - 14s - loss: 5999.5960 - val_loss: 5999.4660\n",
      "Epoch 15/20\n",
      " - 14s - loss: 5999.5953 - val_loss: 5999.4239\n",
      "Epoch 16/20\n",
      " - 14s - loss: 5999.5950 - val_loss: 5999.5976\n",
      "Epoch 17/20\n",
      " - 14s - loss: 5999.5943 - val_loss: 5999.4981\n",
      "Epoch 18/20\n",
      " - 14s - loss: 5999.5941 - val_loss: 5999.2932\n",
      "Epoch 19/20\n",
      " - 14s - loss: 5999.5934 - val_loss: 5999.3898\n",
      "Epoch 20/20\n",
      " - 14s - loss: 5999.5935 - val_loss: 5999.5709\n",
      "Test accuracy: 5999.5709627604165\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 24s - loss: 5312.2083 - val_loss: 5268.4521\n",
      "Epoch 2/20\n",
      " - 14s - loss: 5268.5602 - val_loss: 5268.7897\n",
      "Epoch 3/20\n",
      " - 14s - loss: 5268.5503 - val_loss: 5268.3272\n",
      "Epoch 4/20\n",
      " - 14s - loss: 5268.5420 - val_loss: 5268.8422\n",
      "Epoch 5/20\n",
      " - 14s - loss: 5268.5372 - val_loss: 5268.4584\n",
      "Epoch 6/20\n",
      " - 14s - loss: 5268.5330 - val_loss: 5268.4683\n",
      "Epoch 7/20\n",
      " - 14s - loss: 5268.5295 - val_loss: 5268.4852\n",
      "Epoch 8/20\n",
      " - 14s - loss: 5268.5280 - val_loss: 5268.5119\n",
      "Epoch 9/20\n",
      " - 14s - loss: 5268.5261 - val_loss: 5268.4803\n",
      "Epoch 10/20\n",
      " - 14s - loss: 5268.5242 - val_loss: 5268.0584\n",
      "Epoch 11/20\n",
      " - 14s - loss: 5268.5231 - val_loss: 5268.7314\n",
      "Epoch 12/20\n",
      " - 14s - loss: 5268.5221 - val_loss: 5268.4363\n",
      "Epoch 13/20\n",
      " - 14s - loss: 5268.5216 - val_loss: 5268.4019\n",
      "Epoch 14/20\n",
      " - 14s - loss: 5268.5200 - val_loss: 5268.5959\n",
      "Epoch 15/20\n",
      " - 14s - loss: 5268.5201 - val_loss: 5268.3218\n",
      "Epoch 16/20\n",
      " - 14s - loss: 5268.5196 - val_loss: 5268.4768\n",
      "Epoch 17/20\n",
      " - 14s - loss: 5268.5189 - val_loss: 5268.2038\n",
      "Epoch 18/20\n",
      " - 14s - loss: 5268.5189 - val_loss: 5268.6211\n",
      "Epoch 19/20\n",
      " - 14s - loss: 5268.5185 - val_loss: 5268.4358\n",
      "Epoch 20/20\n",
      " - 14s - loss: 5268.5178 - val_loss: 5268.3505\n",
      "Test accuracy: 5268.3504817708335\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 25s - loss: 4628.1475 - val_loss: 4584.4221\n",
      "Epoch 2/20\n",
      " - 14s - loss: 4584.4626 - val_loss: 4584.5909\n",
      "Epoch 3/20\n",
      " - 14s - loss: 4584.4607 - val_loss: 4584.6540\n",
      "Epoch 4/20\n",
      " - 14s - loss: 4584.4595 - val_loss: 4584.6599\n",
      "Epoch 5/20\n",
      " - 14s - loss: 4584.4589 - val_loss: 4584.6604\n",
      "Epoch 6/20\n",
      " - 14s - loss: 4584.4581 - val_loss: 4584.3888\n",
      "Epoch 7/20\n",
      " - 14s - loss: 4584.4576 - val_loss: 4584.2888\n",
      "Epoch 8/20\n",
      " - 14s - loss: 4584.4568 - val_loss: 4584.1476\n",
      "Epoch 9/20\n",
      " - 14s - loss: 4584.4560 - val_loss: 4584.2915\n",
      "Epoch 10/20\n",
      " - 14s - loss: 4584.4557 - val_loss: 4584.7304\n",
      "Epoch 11/20\n",
      " - 14s - loss: 4584.4551 - val_loss: 4584.6948\n",
      "Epoch 12/20\n",
      " - 14s - loss: 4584.4544 - val_loss: 4584.4182\n",
      "Epoch 13/20\n",
      " - 14s - loss: 4584.4538 - val_loss: 4584.9309\n",
      "Epoch 14/20\n",
      " - 14s - loss: 4584.4539 - val_loss: 4584.3047\n",
      "Epoch 15/20\n",
      " - 14s - loss: 4584.4532 - val_loss: 4584.3582\n",
      "Epoch 16/20\n",
      " - 14s - loss: 4584.4526 - val_loss: 4584.7259\n",
      "Epoch 17/20\n",
      " - 14s - loss: 4584.4528 - val_loss: 4584.2321\n",
      "Epoch 18/20\n",
      " - 14s - loss: 4584.4523 - val_loss: 4584.0216\n",
      "Epoch 19/20\n",
      " - 14s - loss: 4584.4520 - val_loss: 4584.5077\n",
      "Epoch 20/20\n",
      " - 14s - loss: 4584.4517 - val_loss: 4584.6539\n",
      "Test accuracy: 4584.653871614583\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 25s - loss: 5662.7395 - val_loss: 5619.4250\n",
      "Epoch 2/20\n",
      " - 14s - loss: 5619.3923 - val_loss: 5619.3479\n",
      "Epoch 3/20\n",
      " - 14s - loss: 5619.3896 - val_loss: 5619.3241\n",
      "Epoch 4/20\n",
      " - 14s - loss: 5619.3886 - val_loss: 5619.2033\n",
      "Epoch 5/20\n",
      " - 14s - loss: 5619.3875 - val_loss: 5619.6674\n",
      "Epoch 6/20\n",
      " - 13s - loss: 5619.3868 - val_loss: 5619.4088\n",
      "Epoch 7/20\n",
      " - 13s - loss: 5619.3859 - val_loss: 5619.3956\n",
      "Epoch 8/20\n",
      " - 13s - loss: 5619.3846 - val_loss: 5619.2060\n",
      "Epoch 9/20\n",
      " - 13s - loss: 5619.3839 - val_loss: 5619.4504\n",
      "Epoch 10/20\n",
      " - 13s - loss: 5619.3834 - val_loss: 5619.2136\n",
      "Epoch 11/20\n",
      " - 13s - loss: 5619.3826 - val_loss: 5619.5744\n",
      "Epoch 12/20\n",
      " - 13s - loss: 5619.3820 - val_loss: 5619.7177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      " - 13s - loss: 5619.3815 - val_loss: 5619.8683\n",
      "Epoch 14/20\n",
      " - 13s - loss: 5619.3812 - val_loss: 5619.3584\n",
      "Epoch 15/20\n",
      " - 13s - loss: 5619.3809 - val_loss: 5619.4116\n",
      "Epoch 16/20\n",
      " - 13s - loss: 5619.3807 - val_loss: 5619.6034\n",
      "Epoch 17/20\n",
      " - 13s - loss: 5619.3804 - val_loss: 5619.6326\n",
      "Epoch 18/20\n",
      " - 13s - loss: 5619.3797 - val_loss: 5619.3235\n",
      "Epoch 19/20\n",
      " - 14s - loss: 5619.3797 - val_loss: 5619.0162\n",
      "Epoch 20/20\n",
      " - 14s - loss: 5619.3790 - val_loss: 5619.3289\n",
      "Test accuracy: 5619.328918489583\n",
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      " - 25s - loss: 6272.5727 - val_loss: 6228.5086\n",
      "Epoch 2/20\n",
      " - 14s - loss: 6228.7251 - val_loss: 6228.5231\n",
      "Epoch 3/20\n",
      " - 14s - loss: 6228.7203 - val_loss: 6228.9628\n",
      "Epoch 4/20\n",
      " - 14s - loss: 6228.7168 - val_loss: 6228.9038\n",
      "Epoch 5/20\n",
      " - 14s - loss: 6228.7142 - val_loss: 6229.0622\n",
      "Epoch 6/20\n",
      " - 14s - loss: 6228.7103 - val_loss: 6228.4396\n",
      "Epoch 7/20\n",
      " - 14s - loss: 6228.7092 - val_loss: 6228.3376\n",
      "Epoch 8/20\n",
      " - 14s - loss: 6228.7067 - val_loss: 6228.9570\n",
      "Epoch 9/20\n",
      " - 14s - loss: 6228.7058 - val_loss: 6228.0501\n",
      "Epoch 10/20\n",
      " - 14s - loss: 6228.7043 - val_loss: 6229.6898\n",
      "Epoch 11/20\n",
      " - 14s - loss: 6228.7026 - val_loss: 6228.2360\n",
      "Epoch 12/20\n",
      " - 14s - loss: 6228.7020 - val_loss: 6227.9665\n",
      "Epoch 13/20\n",
      " - 14s - loss: 6228.7014 - val_loss: 6228.8253\n",
      "Epoch 14/20\n",
      " - 14s - loss: 6228.7005 - val_loss: 6228.2536\n",
      "Epoch 15/20\n",
      " - 14s - loss: 6228.6998 - val_loss: 6227.8896\n",
      "Epoch 16/20\n",
      " - 14s - loss: 6228.6996 - val_loss: 6228.6466\n",
      "Epoch 17/20\n",
      " - 14s - loss: 6228.6985 - val_loss: 6228.6207\n",
      "Epoch 18/20\n",
      " - 14s - loss: 6228.6986 - val_loss: 6228.0691\n",
      "Epoch 19/20\n",
      " - 14s - loss: 6228.6979 - val_loss: 6228.6136\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c3ffc78f13c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                       notebook_name='Trial 2')\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    137\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     )\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         )\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[1;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[1;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/home/deepak_sadulla/notebooks/Kaggle/santander/notebooks/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=100,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Trial 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Dropout, PReLU, Concatenate, concatenate, multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.constraints import nonneg\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, confusion_matrix, accuracy_score\n",
    "\n",
    "import pickle, sys, h5py, numpy\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "numpy.random.seed(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Training Data\n",
    "df = pd.read_csv(\"../data/train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Testing Data\n",
    "df_test = pd.read_csv(\"../data/test.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../results/BestModel1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df- (200000, 202)\n",
      "df- Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
      "       'var_5', 'var_6', 'var_7',\n",
      "       ...\n",
      "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
      "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
      "      dtype='object', length=202)\n",
      "Index(['ID_code', 'target'], dtype='object')\n",
      "Index(['var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7',\n",
      "       'var_8', 'var_9',\n",
      "       ...\n",
      "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
      "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
      "      dtype='object', length=200)\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checks\n",
    "print(\"df-\",df.shape)\n",
    "print(\"df-\",df.columns)\n",
    "\n",
    "print(df.columns[0:2])\n",
    "print(df.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[2:]].astype(float).values\n",
    "y_clf = np.array(df['target']).astype(float)\n",
    "\n",
    "X_test = df_test[df_test.columns[1:]].astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_backup = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaler_x_test = MinMaxScaler(feature_range=(0, 1))\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 200)\n",
      "(200000,)\n",
      "(200000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_clf.shape)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model = Input(shape = (X.shape[1],))\n",
    "\n",
    "output_model = Dense(512, activation='relu')(input_model)\n",
    "output_model = Dense(256, activation='relu')(output_model)\n",
    "output_model = Dense(128, activation='relu')(output_model)\n",
    "output_model = Dense(1, activation='sigmoid')(output_model)\n",
    "\n",
    "model = Model(inputs=input_model, \n",
    "              outputs=output_model)\n",
    "\n",
    "lr1 = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=lr1,\n",
    "              metrics = ['binary_accuracy'])\n",
    "\n",
    "MCP = ModelCheckpoint(filepath = \"../results/BestModel1.h5\", monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                      save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "RLROP = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, \n",
    "                          mode='auto', min_delta=0.00001, cooldown=1, min_lr=0)\n",
    "\n",
    "CSVL = CSVLogger(filename = \"../results/LogFile1.txt\", separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "140000/140000 [==============================] - 11s 75us/step - loss: 0.3022 - binary_accuracy: 0.8961 - val_loss: 0.2696 - val_binary_accuracy: 0.9055\n",
      "Epoch 2/100\n",
      "140000/140000 [==============================] - 10s 73us/step - loss: 0.2395 - binary_accuracy: 0.9120 - val_loss: 0.2327 - val_binary_accuracy: 0.9137\n",
      "Epoch 3/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2392 - binary_accuracy: 0.9124 - val_loss: 0.2323 - val_binary_accuracy: 0.9138\n",
      "Epoch 4/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2338 - binary_accuracy: 0.9138 - val_loss: 0.2362 - val_binary_accuracy: 0.9116\n",
      "Epoch 5/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2345 - binary_accuracy: 0.9136 - val_loss: 0.2333 - val_binary_accuracy: 0.9132\n",
      "Epoch 6/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2364 - binary_accuracy: 0.9128 - val_loss: 0.2353 - val_binary_accuracy: 0.9123\n",
      "Epoch 7/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2360 - binary_accuracy: 0.9131 - val_loss: 0.2371 - val_binary_accuracy: 0.9113\n",
      "Epoch 8/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2340 - binary_accuracy: 0.9140 - val_loss: 0.2382 - val_binary_accuracy: 0.9109\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2307 - binary_accuracy: 0.9148 - val_loss: 0.2315 - val_binary_accuracy: 0.9140\n",
      "Epoch 10/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2299 - binary_accuracy: 0.9150 - val_loss: 0.2315 - val_binary_accuracy: 0.9140\n",
      "Epoch 11/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2297 - binary_accuracy: 0.9152 - val_loss: 0.2313 - val_binary_accuracy: 0.9139\n",
      "Epoch 12/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2297 - binary_accuracy: 0.9152 - val_loss: 0.2313 - val_binary_accuracy: 0.9140\n",
      "Epoch 13/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2296 - binary_accuracy: 0.9151 - val_loss: 0.2349 - val_binary_accuracy: 0.9120\n",
      "Epoch 14/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2298 - binary_accuracy: 0.9152 - val_loss: 0.2334 - val_binary_accuracy: 0.9132\n",
      "Epoch 15/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2296 - binary_accuracy: 0.9153 - val_loss: 0.2310 - val_binary_accuracy: 0.9139\n",
      "Epoch 16/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2293 - binary_accuracy: 0.9153 - val_loss: 0.2314 - val_binary_accuracy: 0.9139\n",
      "Epoch 17/100\n",
      "140000/140000 [==============================] - 11s 77us/step - loss: 0.2293 - binary_accuracy: 0.9154 - val_loss: 0.2324 - val_binary_accuracy: 0.9129\n",
      "Epoch 18/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2290 - binary_accuracy: 0.9155 - val_loss: 0.2310 - val_binary_accuracy: 0.9138\n",
      "Epoch 19/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2288 - binary_accuracy: 0.9155 - val_loss: 0.2308 - val_binary_accuracy: 0.9142\n",
      "Epoch 20/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2290 - binary_accuracy: 0.9155 - val_loss: 0.2309 - val_binary_accuracy: 0.9139 binary_\n",
      "Epoch 21/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2286 - binary_accuracy: 0.9159 - val_loss: 0.2307 - val_binary_accuracy: 0.9134\n",
      "Epoch 22/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2285 - binary_accuracy: 0.9155 - val_loss: 0.2319 - val_binary_accuracy: 0.9130\n",
      "Epoch 23/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2281 - binary_accuracy: 0.9158 - val_loss: 0.2306 - val_binary_accuracy: 0.9139\n",
      "Epoch 24/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2283 - binary_accuracy: 0.9157 - val_loss: 0.2305 - val_binary_accuracy: 0.9139\n",
      "Epoch 25/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2280 - binary_accuracy: 0.9156 - val_loss: 0.2304 - val_binary_accuracy: 0.9139\n",
      "Epoch 26/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2276 - binary_accuracy: 0.9158 - val_loss: 0.2308 - val_binary_accuracy: 0.9139\n",
      "Epoch 27/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2271 - binary_accuracy: 0.9159 - val_loss: 0.2302 - val_binary_accuracy: 0.9138\n",
      "Epoch 28/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2274 - binary_accuracy: 0.9160 - val_loss: 0.2311 - val_binary_accuracy: 0.9137\n",
      "Epoch 29/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2271 - binary_accuracy: 0.9160 - val_loss: 0.2301 - val_binary_accuracy: 0.9139\n",
      "Epoch 30/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2264 - binary_accuracy: 0.9164 - val_loss: 0.2301 - val_binary_accuracy: 0.9138\n",
      "Epoch 31/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2260 - binary_accuracy: 0.9166 - val_loss: 0.2301 - val_binary_accuracy: 0.9138\n",
      "Epoch 32/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2259 - binary_accuracy: 0.9168 - val_loss: 0.2299 - val_binary_accuracy: 0.9139\n",
      "Epoch 33/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2256 - binary_accuracy: 0.9168 - val_loss: 0.2326 - val_binary_accuracy: 0.9127\n",
      "Epoch 34/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2254 - binary_accuracy: 0.9166 - val_loss: 0.2301 - val_binary_accuracy: 0.9140\n",
      "Epoch 35/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2260 - binary_accuracy: 0.9167 - val_loss: 0.2297 - val_binary_accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2248 - binary_accuracy: 0.9169 - val_loss: 0.2344 - val_binary_accuracy: 0.9123\n",
      "Epoch 37/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2240 - binary_accuracy: 0.9173 - val_loss: 0.2306 - val_binary_accuracy: 0.9138\n",
      "Epoch 38/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2233 - binary_accuracy: 0.9175 - val_loss: 0.2304 - val_binary_accuracy: 0.9140\n",
      "Epoch 39/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2227 - binary_accuracy: 0.9175 - val_loss: 0.2305 - val_binary_accuracy: 0.9139\n",
      "Epoch 40/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2231 - binary_accuracy: 0.9177 - val_loss: 0.2314 - val_binary_accuracy: 0.9136\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 41/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2213 - binary_accuracy: 0.9184 - val_loss: 0.2293 - val_binary_accuracy: 0.9143\n",
      "Epoch 42/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2209 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9143\n",
      "Epoch 43/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2208 - binary_accuracy: 0.9184 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "Epoch 44/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2207 - binary_accuracy: 0.9185 - val_loss: 0.2294 - val_binary_accuracy: 0.9141\n",
      "Epoch 45/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2207 - binary_accuracy: 0.9185 - val_loss: 0.2294 - val_binary_accuracy: 0.9141\n",
      "Epoch 46/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2206 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 47/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2205 - binary_accuracy: 0.9186 - val_loss: 0.2294 - val_binary_accuracy: 0.9145\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 48/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2204 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "Epoch 49/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "Epoch 50/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 51/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 53/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 54/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 55/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 56/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "Epoch 57/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 58/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 59/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 60/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 61/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 62/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 63/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 64/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 65/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144s - loss: 0.2198\n",
      "Epoch 66/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 67/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 68/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 69/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 70/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 71/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 72/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 73/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 74/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 75/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 76/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 77/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "Epoch 78/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 79/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 80/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 81/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 82/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "Epoch 83/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 84/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 85/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144loss: 0.2203 - binary_\n",
      "Epoch 86/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 87/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "Epoch 88/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 89/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 90/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 91/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 92/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 94/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 96/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 97/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "Epoch 98/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 99/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 100/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b014912e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100 # 20\n",
    "\n",
    "model.fit(x = X, \n",
    "          y = y_clf,\n",
    "          validation_split = 0.3,\n",
    "          epochs=epochs, \n",
    "          batch_size= 1024,\n",
    "          callbacks = [MCP, RLROP, CSVL],\n",
    "          verbose = 1,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2208 - binary_accuracy: 0.9185 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 2/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2207 - binary_accuracy: 0.9185 - val_loss: 0.2293 - val_binary_accuracy: 0.9143\n",
      "Epoch 3/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2207 - binary_accuracy: 0.9184 - val_loss: 0.2293 - val_binary_accuracy: 0.9146\n",
      "Epoch 4/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2207 - binary_accuracy: 0.9185 - val_loss: 0.2296 - val_binary_accuracy: 0.9141\n",
      "Epoch 5/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2205 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 6/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2205 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 7/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2203 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9143\n",
      "Epoch 8/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2203 - binary_accuracy: 0.9186 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "Epoch 9/100\n",
      "140000/140000 [==============================] - 10s 73us/step - loss: 0.2202 - binary_accuracy: 0.9186 - val_loss: 0.2294 - val_binary_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "140000/140000 [==============================] - 11s 77us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9145\n",
      "Epoch 11/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2294 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 12/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.914402 - binary_accuracy: 0.\n",
      "Epoch 13/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 14/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 15/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 16/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 17/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 18/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 19/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 20/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 21/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 22/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 23/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 24/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144 - bi - ETA: 1s - loss: 0.2\n",
      "Epoch 25/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 26/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 27/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 28/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 29/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 30/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 31/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 32/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 33/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 34/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 35/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "Epoch 37/100\n",
      "140000/140000 [==============================] - 10s 71us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 38/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 39/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 40/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 41/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "Epoch 42/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 43/100\n",
      "140000/140000 [==============================] - 10s 72us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 44/100\n",
      "140000/140000 [==============================] - 10s 73us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 46/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "Epoch 47/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 48/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 49/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 50/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 51/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "Epoch 52/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 53/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 54/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 55/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 56/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "Epoch 57/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 58/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 59/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 60/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 61/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "Epoch 62/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 63/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 64/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 65/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 66/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "Epoch 67/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 68/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.91442202 - binary_accuracy: 0\n",
      "Epoch 69/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 70/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 71/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "Epoch 72/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 73/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 74/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 75/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 76/100\n",
      "140000/140000 [==============================] - 9s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "Epoch 77/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 78/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 79/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 80/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 81/100\n",
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "Epoch 82/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 83/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 84/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 85/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 86/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "Epoch 87/100\n",
      "140000/140000 [==============================] - 10s 69us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 88/100\n",
      "140000/140000 [==============================] - 10s 70us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 10s 68us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 90/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 91/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "Epoch 92/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 93/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 94/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 96/100\n",
      "140000/140000 [==============================] - 9s 66us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "Epoch 97/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 98/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 99/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n",
      "Epoch 100/100\n",
      "140000/140000 [==============================] - 9s 67us/step - loss: 0.2202 - binary_accuracy: 0.9187 - val_loss: 0.2293 - val_binary_accuracy: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b025c2da0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100 # 20\n",
    "\n",
    "model.fit(x = X, \n",
    "          y = y_clf,\n",
    "          validation_split = 0.3,\n",
    "          epochs=epochs, \n",
    "          batch_size= 1024,\n",
    "          callbacks = [MCP, RLROP, CSVL],\n",
    "          verbose = 1,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 4s 18us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22326479040145875, 0.91733]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On Training Data\n",
    "model.evaluate(x = X, \n",
    "               y = y_clf,\n",
    "              batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"../results/BestModel1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 4s 18us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22326479040145875, 0.91733]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On Training Data\n",
    "best_model.evaluate(x = X, \n",
    "               y = y_clf,\n",
    "              batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = model\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X, batch_size = 1024)\n",
    "\n",
    "y_test_preds = model.predict(X_test, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0.02684054, 0.7223495 , 0.04017243, ..., 0.09523162, 0.02365717,\n",
       "        0.00561482], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_clf,y_preds.reshape(y_preds.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8720867789797286"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_clf,y_preds.reshape(y_preds.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "old_model.save('../results/Trial1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to threshold for an imbalanced problem\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09574279189109802"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = Find_Optimal_Cutoff(y_clf, y_preds)[0]\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = np.where(y_preds>threshold,1,0).reshape(-1)\n",
    "y_test_p = np.where(y_test_preds>threshold,1,0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142280,  37622],\n",
       "       [  4204,  15894]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_clf, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79087"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_clf == y_p).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158174"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_clf,y_p, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_results = pd.DataFrame({'ID_code' : df['ID_code'].tolist(),'actual' : y_clf,'pred' : y_preds[:,0]})\n",
    "\n",
    "Train_results.to_csv(\"../results/TrainResults_Trial1.csv\", index = False)\n",
    "\n",
    "Test_results = pd.DataFrame({'ID_code' : df_test['ID_code'].tolist(),'target' : y_test_p})\n",
    "\n",
    "Test_results.to_csv(\"../results/TestResults_Trial1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_code', 'actual', 'pred'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_code', 'target'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>actual</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  actual      pred\n",
       "0  train_0     0.0  0.026841\n",
       "1  train_1     0.0  0.722350\n",
       "2  train_2     0.0  0.040172\n",
       "3  train_3     0.0  0.244595\n",
       "4  train_4     0.0  0.084650"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target\n",
       "0  test_0       1\n",
       "1  test_1       1\n",
       "2  test_2       0\n",
       "3  test_3       1\n",
       "4  test_4       0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
